---
layout: post
title: "数据科学之机器学习7: 决策树"
date: 2014-04-11 19:00:32 +0800
comments: true
categories: DataScience MachineLearning DecisionTree Classification
---

![article 21](/images/article/article21.jpg)
<!-- more -->

*“文章原创，转载请注明出处”*

***

### 一、开始
***

在介绍决策树的概念内容之前，先来初步了解一下决策树的流程。这是一个很简单的概念，通过一张简单的流程图就可以大致了解决策树是干什么的，怎么干的。

![decision trees](\images\a21\decisiontrees.jpg)

### 二、相关概念
***

#### 1. 一些概念
***

* 决策树学习是一种逼近离散值目标函数的方法。
* 决策树通过把实例从根节点排列到某个叶子节点来分类实例，叶子的节点即为实例所属的分类。
* 决策树上的每一个节点，指定了对实例的某一个属性的测试，并且，该节点的每一个后续分支对应该属性的一个可能值。

#### 2. 分类方法
***
从树的根节点开始，测试这个节点指定的属性，然后按照给定实例的该属性值对应的分支向下移动。然后以新节点作为根节点重复上面的过程直至结束。

### 三、 评价
***

通过决策树的流程，可以发现决策树的计算复杂度不高，而且其输出的结果易于理解，并且对缺失值不敏感。

但是，正是由于其划分过于细致，可能会导致过度匹配问题(与回归中的overfitting类似)。

### 四、主要的决策树算法
***

从决策树的流程可以看出，**如何选择属性作为节点以测试实例**是最为关键的一步。不同的算法采取了不同的方法，主要的决策树算法有这样几个：

* ID3
* C4.5 （数据挖掘十大算法之一，也是ID3算法的改进）
* C5.0 （C4.5的改进，适用于处理大数据集，采用Boosting方式提高模型准确率，因而又称BoostingTrees。）
* CART（数据挖掘十大算法之一）

下一篇就开始讲讲一些决策树的算法。