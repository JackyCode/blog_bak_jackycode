---
layout: post
title: "数据科学之机器学习17:因子分析2"
date: 2014-05-19 15:00:02 +0800
comments: true
categories: DataScience MachineLearning
---

![article 35](/images/article/article35.jpg)
<!-- more -->

图片来源于[网址](http://software.ssri.co.jp/statweb2/column/column0811.html)

*“文章原创，转载请注明出处”*

***

这两天来了个同学，大家聚了聚，我也乘机休息了两天（好奢侈！）。这两天属于什么都没有写，就翻看了两本书。一本是二月河的[康熙大帝](http://www.amazon.cn/gp/product/B0032K0X6Q/ref=olp_product_details?ie=UTF8&me=&seller=)，另外一本是[推荐系统实践](http://www.ituring.com.cn/book/894)，这本书的电子版，图灵正在打折，有兴趣可以买本看看。

***

好了，不废话了，下面就接着上一篇讲的继续！上一篇简单介绍了因子分析的一些概念，以及最基础的因子模型：**正交因子模型**。那么这一篇，就来说说正交因子模型的**参数估计问题**。

对于一组p维样本，有n个观测值：$$x_1, x_2, \dots, x_n$$，则其均值和协方差矩阵可以使用样本均值和样本协方差矩阵来估计：

$$ \hat{\mu} = \overline{x} = \frac{1}{n} {\sum_{i=1}^{n} x_i} $$

$$ \hat{\Sigma} = S = \frac{1}{n-1} {\sum_{i=1}^{n} (x_i-\overline{x})(x_i-\overline{x})'} $$

在因子模型中，需要估计的有两个参数：**因子载荷矩阵**$$A=(a_{ij}:p \times m)$$以及**特殊方差矩阵**$$D = diag(\sigma_1^2, \sigma_2^2, \dots, \sigma_p^2)$$。

***

#### 1. 主成分法
***

主成分法的思想取自于主成分分析，即是取出前m个成分作为主成分，然后以此来得到因子载荷矩阵的估计；然后再以协方差阵和因子载荷矩阵为条件，直接推出特殊方差矩阵。具体如下：

1. 求出协方差矩阵$$S$$的特征值：$$\hat{\lambda}_1 \geqslant \hat{\lambda}_2 \geqslant \dots \geqslant \hat{\lambda}_p \geqslant 0$$，其对应的特征向量为：$$\hat{t}_1, \hat{t}_2, \dots, \hat{t}_p$$。
2. 选一个较小因子数$$m$$，并且使得前m项累计贡献率$$\frac{\sum_{i=1}^{m} \hat{\lambda}_i}{\sum_{i=1}^{p} \hat{\lambda}_i} $$高于设定值。
3. 将协方差矩阵$$S$$做这样的近似：$$S = \sum_{i=1}^{m} \hat{\lambda}_i + \sum_{i=m+1}^{p} \hat{\lambda}_i \approx \sum_{i=1}^{m} \hat{\lambda}_i + \hat{D} := \hat{A}\hat{A}' + \hat{D} $$

其中，$$A = (\sqrt{\hat{\lambda}_1}t_1, \sqrt{\hat{\lambda}_2}t_2, \dots, \sqrt{\hat{\lambda}_m}t_m) $$,$$\hat{D} = diag(\hat{\sigma}_1^2, \hat{\sigma}_2^2, \dots, \hat{\sigma}_p^2) $$,$$\hat{\sigma}_i^2 = s_{ii} - \sum_{j=1}^{m} \hat{a}_{ij}^2 $$

从上述的过程来看，我们是使用了一种近似的方法估计出了$$A$$和$$D$$，那么这就有一个**残差矩阵**$$S - (\hat{A}\hat{A}' + \hat{D}) $$，显然这个矩阵的对角线元素为0。既然是一种近似，那么，如果这个残差矩阵的非对角线元素都非常小的时候，我们就可以认为取$$m$$个因子的模型就可以很好地解释或者是拟合原始的数据了。

***

#### 2. 主因子法
***

对于因子模型，我们先对原始向量进行标准化，则有：$$ R = AA' + D$$。取**约相关矩阵**$$R^* = R - D = AA'$$，假设特殊方差$$\sigma_i^2$$的一个估计值$$\hat{\sigma}^2$$为初始估计，则有约相关矩阵的估计值为：

![](/images/a35/eq2_1.png)

其中$$\hat{R}$$为样本相关矩阵，$$\hat{D} = diag(\hat{\sigma^2_1},\hat{\sigma_2^2}, \dots, \hat{\sigma_p^2}) $$, $$\hat{h_i^2} = 1 - \hat{\sigma_i^2} $$为$$h_i^2$$的初始估计。

计算$$\hat{R}^*$$的特征值，取足够小，但累计贡献率达到要求的m：$$\hat{\lambda^*_1} \geqslant \hat{\lambda^*_2} \geqslant \dots \geqslant \hat{\lambda^*_m} > 0 $$，其对应的特征向量为：$$\hat{t^*_1}, \hat{t^*_2}, \dots, \hat{t^*_m}$$，则得到 $$A$$ 的估计值：

$$ \hat{A} = (\sqrt{\hat{\lambda^*_1}}t^*_1, \sqrt{\hat{\lambda^*_2}}t^*_2, \dots, \sqrt{\hat{\lambda^*_m}}t^*_m ) $$

那么$$\sigma^2_i$$的最终估计为： $$ \hat{\sigma_i^2} = 1-\hat{h_i^2} = 1 - \sum_{j=1}^{m} \hat{a_{ij}^2} $$。

可以看到，这是一个可以迭代的过程，我们可以一直迭代，直到结果达到稳定为止！从过程来看，这里其实也是利用了主成分，因而，主因子法也是主成分法的一种修正！

那么接下来的问题就是，这个特殊方差$$\sigma^2_i$$的初始估计值应该如何取呢？最常用的取法：$$ \hat{\sigma_i^2} = 1/r^{ii} $$, 其中$$ r^{ii} $$为$$\hat{R}^{-1}$$对角线元素的第$$i$$个。

***

#### 3. 极大似然法
***

使用极大似然估计，那么就肯定需要使用样本的分布，这里我们假定公共因子$$f \sim N_m(0, I) $$，特殊因子$$ \varepsilon \sim N_p(0, D) $$，并且相互独立！这里的假设其实就是来源于模型的正交性假设，只不过是将正交性假设进一步限定，假设它们都是属于多元正态分布！

有了上述假设，通过模型就可以知道$$x \sim N_p(\mu, \Sigma) $$，有了这个就可以计算样本的似然函数了，这里涉及到较为复杂的矩阵计算，不想多说，有兴趣的话可以查找一些资料；或者学习一下线性模型中关于矩阵求导的知识，然后自己推导一下。

一般情况下，极大似然法使用得并不太多，因为这个方法是算不出显式解的，在没有限制条件的情况下，解也并不唯一确定！但是如果是在因子分部可以明显知道的情况下，使用这个方法就比较好了！

***

### 总结
***

到这边，对于基础的因子模型就介绍结束了。回顾一下，主要就是介绍了正交因子模型以及它的参数估计问题。但是，到这里，我们还没有说到模型中的公共因子如何解释这个问题！对于这个问题的解释，通常结合实际的问题，需要一定的专业知识和经验，然后才能给每个公共因子给出一个实际意义。而且，公共因子的解释，在很大程度上也依赖于因子模型中因子载荷矩阵的元素结构！这个时候就会牵扯出因子分析中其它的一些问题：**因子旋转**和**因子得分**。因为这两个问题涉及到一些比较复杂的数学知识，我不能够在清减数学的情况下说好它，如果单说怎么用，我觉得没有必要，所以暂时并不打算介绍这两个问题。有兴趣的，可以翻阅一些多元统计的书籍，一般都会有讲。