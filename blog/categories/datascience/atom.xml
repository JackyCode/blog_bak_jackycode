<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: DataScience | Jacky and MSC]]></title>
  <link href="http://jackycode.github.io/blog/categories/datascience/atom.xml" rel="self"/>
  <link href="http://jackycode.github.io/"/>
  <updated>2014-06-18T15:36:25+08:00</updated>
  <id>http://jackycode.github.io/</id>
  <author>
    <name><![CDATA[Jacky Code]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[数据科学18：文本挖掘1]]></title>
    <link href="http://jackycode.github.io/blog/2014/06/18/text-mining1/"/>
    <updated>2014-06-18T15:08:39+08:00</updated>
    <id>http://jackycode.github.io/blog/2014/06/18/text-mining1</id>
    <content type="html"><![CDATA[<p><img src="/images/article/article40.jpg" alt="article 40" />
<!-- more --></p>

<p>图片由本文中数据生产~</p>

<p><em>“文章原创，转载请注明出处”</em></p>

<hr />

<p><strong>文本挖掘</strong>，也称为文本数据挖掘，意思就如字面，对文本数据进行挖掘分析。文本挖掘一般包含：<em>文本分类</em>、<em>文本聚类</em>、<em>概念实体挖掘</em>、<em>自然语言处理</em>等等。接下来，我打算用一个简单的例子，介绍一下R语言文本挖掘的一般过程，顺便介绍一些文本挖掘中的概念。</p>

<p>这边主要使用R中的<code>tm</code>包进行文本挖掘，首先加载Package：</p>

<p><code>r
require(tm)  ## R中处理文本挖掘的框架包
require(ggplot2)
</code></p>

<h3 id="corpus">1. 载入Corpus</h3>
<hr />

<p><strong>Corpus</strong>（语料库），指一系列文档的集合，是<code>tm</code>包管理文件的数据结构。通常，我们需要将一批文档导入成Corpus结构的数据，然后才能进行进一步的处理分析。</p>

<p>文档的格式有非常多的格式，<code>tm</code>包支持的格式其实只占很少的一部分，大致有：text, PDF, Mircosoft Word和XML。所以，如果需要处理的文档，其格式不在这里面的话，就需要对格式进行一些转换。个人建议，将文档格式转换成text或者XML会比较容易处理。我们可以查看一下，<code>tm</code>包支持的文档格式：</p>

<p><code>r
getReaders()
</code></p>

<p><code>
## [1] "readDOC"                 "readPDF"
## [3] "readReut21578XML"        "readReut21578XMLasPlain"
## [5] "readPlain"               "readRCV1"
## [7] "readRCV1asPlain"         "readTabular"
## [9] "readXML"
</code></p>

<p>在<code>tm</code>包中，Corpus可以分为两种。一种是Volatile Corpus，这种数据结构是作为R对象保存在内存中,使用<code>VCorpus()</code>或者<code>Corpus()</code>函数；另一种就是Permanent Corpus，作为R的外部保存，使用<code>PCorpus()</code>函数。显然，如何选择取决于内存大小以及运算速率的要求了。</p>

<p>我们这里使用<code>tm</code>包自带的XML文档数据进行演示：</p>

<p><code>r
xml &lt;- system.file("texts", "crude", package = "tm")  ## 数据所在的目录
docs &lt;- Corpus(DirSource(xml), readerControl = list(reader = readReut21578XML))
</code></p>

<p>这里使用的数据源是<code>DirSource</code>，当然也可以从其他的数据源导入，可以使用<code>getSources()</code>查看：</p>

<p><code>r
getSources()
</code></p>

<p><code>
## [1] "DataframeSource" "DirSource"       "ReutersSource"   "URISource"
## [5] "VectorSource"
</code></p>

<p>如果读取的是其他格式的，就需要指定一些其他的参数，用<code>path</code>表示数据所在的目录：</p>

<p><code>r
## txt
docs &lt;- Corpus(DirSource(&lt;path&gt;))
## PDF
docs &lt;- Corpus(DirSource(&lt;path&gt;), readerControl = list(reader = readPDF))
## 其它的类似
</code></p>

<h3 id="corpus-1">2. 查看Corpus</h3>
<hr />

<p>将数据导入成Corpus之后，我们就需要查看Corpus。</p>

<p><code>r
docs  ## 只显示了Corpus中含有的文档数据数量
</code></p>

<p><code>
## A corpus with 20 text documents
</code></p>

<p><code>r
names(docs)[1:3]  ## 显示前3个文档的名称
</code></p>

<p><code>
## [1] "reut-00001.xml" "reut-00002.xml" "reut-00004.xml"
</code></p>

<p><code>r
summary(docs)  ## 显示更多的meta data，但不显示源信息
</code></p>

<p><code>
## A corpus with 20 text documents
##
## The metadata consists of 2 tag-value pairs and a data frame
## Available tags are:
##   create_date creator
## Available variables in the data frame are:
##   MetaID
</code></p>

<p><code>r
inspect(docs[1])  ## 提取第一篇文档的完整信息、
</code></p>

<p><code>
## A corpus with 1 text document
##
## The metadata consists of 2 tag-value pairs and a data frame
## Available tags are:
##   create_date creator
## Available variables in the data frame are:
##   MetaID
##
## $`reut-00001.xml`
## $doc
## $file
## [1] "&lt;buffer&gt;"
##
## $version
## [1] "1.0"
##
## $children
## $children$REUTERS
## &lt;REUTERS TOPICS="YES" LEWISSPLIT="TRAIN" CGISPLIT="TRAINING-SET" OLDID="5670" NEWID="127"&gt;
##  &lt;DATE&gt;26-FEB-1987 17:00:56.04&lt;/DATE&gt;
##  &lt;TOPICS&gt;
##   &lt;D&gt;crude&lt;/D&gt;
##  &lt;/TOPICS&gt;
##  &lt;PLACES&gt;
##   &lt;D&gt;usa&lt;/D&gt;
##  &lt;/PLACES&gt;
##  &lt;PEOPLE/&gt;
##  &lt;ORGS/&gt;
##  &lt;EXCHANGES/&gt;
##  &lt;COMPANIES/&gt;
##  &lt;UNKNOWN&gt;Y
##    f0119 reute
## u f BC-DIAMOND-SHAMROCK-(DIA   02-26 0097&lt;/UNKNOWN&gt;
##  &lt;TEXT&gt;
##   &lt;TITLE&gt;DIAMOND SHAMROCK (DIA) CUTS CRUDE PRICES&lt;/TITLE&gt;
##   &lt;DATELINE&gt;NEW YORK, FEB 26 -&lt;/DATELINE&gt;
##   &lt;BODY&gt;Diamond Shamrock Corp said that
## effective today it had cut its contract prices for crude oil by
## 1.50 dlrs a barrel.
##     The reduction brings its posted price for West Texas
## Intermediate to 16.00 dlrs a barrel, the copany said.
##     &amp;quot;The price reduction today was made in the light of falling
## oil product prices and a weak crude oil market,&amp;quot; a company
## spokeswoman said.
##     Diamond is the latest in a line of U.S. oil companies that
## have cut its contract, or posted, prices over the last two days
## citing weak oil markets.
##  Reuter&lt;/BODY&gt;
##  &lt;/TEXT&gt;
## &lt;/REUTERS&gt;
##
##
## attr(,"class")
## [1] "XMLDocumentContent"
##
## $dtd
## $external
## NULL
##
## $internal
## NULL
##
## attr(,"class")
## [1] "DTDList"
##
## attr(,"Author")
## character(0)
## attr(,"DateTimeStamp")
## [1] "1987-02-26 17:00:56 GMT"
## attr(,"Description")
## [1] ""
## attr(,"Heading")
## [1] "DIAMOND SHAMROCK (DIA) CUTS CRUDE PRICES"
## attr(,"ID")
## [1] "127"
## attr(,"Language")
## [1] "en"
## attr(,"LocalMetaData")
## attr(,"LocalMetaData")$TOPICS
## [1] "YES"
##
## attr(,"LocalMetaData")$LEWISSPLIT
## [1] "TRAIN"
##
## attr(,"LocalMetaData")$CGISPLIT
## [1] "TRAINING-SET"
##
## attr(,"LocalMetaData")$OLDID
## [1] "5670"
##
## attr(,"LocalMetaData")$Topics
## [1] "crude"
##
## attr(,"LocalMetaData")$Places
## [1] "usa"
##
## attr(,"LocalMetaData")$People
## character(0)
##
## attr(,"LocalMetaData")$Orgs
## character(0)
##
## attr(,"LocalMetaData")$Exchanges
## character(0)
##
## attr(,"Origin")
## [1] "Reuters-21578 XML"
## attr(,"class")
## [1] "Reuters21578Document" "TextDocument"         "XMLDocument"
## [4] "XMLAbstractDocument"  "oldClass"
</code></p>

<p><code>r
## inspect(docs) 可以提取所有文档的完整信息，不过数据量会很大
docs[[1]]  ## 提取第一个文档
</code></p>

<p><code>
## $doc
## $file
## [1] "&lt;buffer&gt;"
##
## $version
## [1] "1.0"
##
## $children
## $children$REUTERS
## &lt;REUTERS TOPICS="YES" LEWISSPLIT="TRAIN" CGISPLIT="TRAINING-SET" OLDID="5670" NEWID="127"&gt;
##  &lt;DATE&gt;26-FEB-1987 17:00:56.04&lt;/DATE&gt;
##  &lt;TOPICS&gt;
##   &lt;D&gt;crude&lt;/D&gt;
##  &lt;/TOPICS&gt;
##  &lt;PLACES&gt;
##   &lt;D&gt;usa&lt;/D&gt;
##  &lt;/PLACES&gt;
##  &lt;PEOPLE/&gt;
##  &lt;ORGS/&gt;
##  &lt;EXCHANGES/&gt;
##  &lt;COMPANIES/&gt;
##  &lt;UNKNOWN&gt;Y
##    f0119 reute
## u f BC-DIAMOND-SHAMROCK-(DIA   02-26 0097&lt;/UNKNOWN&gt;
##  &lt;TEXT&gt;
##   &lt;TITLE&gt;DIAMOND SHAMROCK (DIA) CUTS CRUDE PRICES&lt;/TITLE&gt;
##   &lt;DATELINE&gt;NEW YORK, FEB 26 -&lt;/DATELINE&gt;
##   &lt;BODY&gt;Diamond Shamrock Corp said that
## effective today it had cut its contract prices for crude oil by
## 1.50 dlrs a barrel.
##     The reduction brings its posted price for West Texas
## Intermediate to 16.00 dlrs a barrel, the copany said.
##     &amp;quot;The price reduction today was made in the light of falling
## oil product prices and a weak crude oil market,&amp;quot; a company
## spokeswoman said.
##     Diamond is the latest in a line of U.S. oil companies that
## have cut its contract, or posted, prices over the last two days
## citing weak oil markets.
##  Reuter&lt;/BODY&gt;
##  &lt;/TEXT&gt;
## &lt;/REUTERS&gt;
##
##
## attr(,"class")
## [1] "XMLDocumentContent"
##
## $dtd
## $external
## NULL
##
## $internal
## NULL
##
## attr(,"class")
## [1] "DTDList"
##
## attr(,"Author")
## character(0)
## attr(,"DateTimeStamp")
## [1] "1987-02-26 17:00:56 GMT"
## attr(,"Description")
## [1] ""
## attr(,"Heading")
## [1] "DIAMOND SHAMROCK (DIA) CUTS CRUDE PRICES"
## attr(,"ID")
## [1] "127"
## attr(,"Language")
## [1] "en"
## attr(,"LocalMetaData")
## attr(,"LocalMetaData")$TOPICS
## [1] "YES"
##
## attr(,"LocalMetaData")$LEWISSPLIT
## [1] "TRAIN"
##
## attr(,"LocalMetaData")$CGISPLIT
## [1] "TRAINING-SET"
##
## attr(,"LocalMetaData")$OLDID
## [1] "5670"
##
## attr(,"LocalMetaData")$Topics
## [1] "crude"
##
## attr(,"LocalMetaData")$Places
## [1] "usa"
##
## attr(,"LocalMetaData")$People
## character(0)
##
## attr(,"LocalMetaData")$Orgs
## character(0)
##
## attr(,"LocalMetaData")$Exchanges
## character(0)
##
## attr(,"Origin")
## [1] "Reuters-21578 XML"
## attr(,"class")
## [1] "Reuters21578Document" "TextDocument"         "XMLDocument"
## [4] "XMLAbstractDocument"  "oldClass"
</code></p>

<p><code>r
## docs[['reut-00001.xml']] 同样可以提取第一个文档
</code></p>

<h3 id="section">3. 信息转化</h3>
<hr />

<p>创建好Corpus后，就需要对其进行一些修改，比如去除标点、停止词等等。这里就需要使用到一个函数<code>tm_map()</code>，其可以将转化函数作用到每一个文档数据上。</p>

<h4 id="section-1">1. 转化为纯文本</h4>

<p>如果Corpus中存储的是非纯文本的数据，比如XML格式的数据，那么就需要先将这些数据转换成纯文本格式:</p>

<p><code>r
docs &lt;- tm_map(docs, as.PlainTextDocument)
docs[[1]]
</code></p>

<p><code>
## DIAMOND SHAMROCK (DIA) CUTS CRUDE PRICES
## NEW YORK, FEB 26 -
## Diamond Shamrock Corp said that
## effective today it had cut its contract prices for crude oil by
## 1.50 dlrs a barrel.
##     The reduction brings its posted price for West Texas
## Intermediate to 16.00 dlrs a barrel, the copany said.
##     "The price reduction today was made in the light of falling
## oil product prices and a weak crude oil market," a company
## spokeswoman said.
##     Diamond is the latest in a line of U.S. oil companies that
## have cut its contract, or posted, prices over the last two days
## citing weak oil markets.
##  Reuter
</code></p>

<h4 id="section-2">2. 去除特殊字符</h4>

<p>在文档数据中，可能会存在这样的字符：”/”、”@”、”-“等等。大部分时候，我们需要将其去除掉：</p>

<p><code>r
for (i in seq(docs)) {
    docs[[i]] &lt;- gsub("/", " ", docs[[i]])
    docs[[i]] &lt;- gsub("@", " ", docs[[i]])
    docs[[i]] &lt;- gsub("-", " ", docs[[i]])
}
</code></p>

<p>如果存在更复杂的替换，可以使用正则表达式去解决，这里不做介绍。</p>

<h4 id="section-3">3. 转换成小写</h4>

<p>顾名思义，就是将所有的数据转换成小写字母，这样以便更加容易分析。</p>

<p><code>r
docs &lt;- tm_map(docs, tolower)
docs[[1]]  ## 查看效果
</code></p>

<p><code>
## diamond shamrock (dia) cuts crude prices
## new york, feb 26
## diamond shamrock corp said that
## effective today it had cut its contract prices for crude oil by
## 1.50 dlrs a barrel.
##     the reduction brings its posted price for west texas
## intermediate to 16.00 dlrs a barrel, the copany said.
##     "the price reduction today was made in the light of falling
## oil product prices and a weak crude oil market," a company
## spokeswoman said.
##     diamond is the latest in a line of u.s. oil companies that
## have cut its contract, or posted, prices over the last two days
## citing weak oil markets.
##  reuter
</code></p>

<h4 id="section-4">4. 去除数字</h4>

<p>有些时候，我们需要将文档中的数字去除掉：</p>

<p><code>r
docs &lt;- tm_map(docs, removeNumbers)
docs[[1]]
</code></p>

<p><code>
## diamond shamrock (dia) cuts crude prices
## new york, feb
## diamond shamrock corp said that
## effective today it had cut its contract prices for crude oil by
## . dlrs a barrel.
##     the reduction brings its posted price for west texas
## intermediate to . dlrs a barrel, the copany said.
##     "the price reduction today was made in the light of falling
## oil product prices and a weak crude oil market," a company
## spokeswoman said.
##     diamond is the latest in a line of u.s. oil companies that
## have cut its contract, or posted, prices over the last two days
## citing weak oil markets.
##  reuter
</code></p>

<h4 id="section-5">5. 去除停止词</h4>

<p><code>r
docs &lt;- tm_map(docs, removeWords, stopwords("english"))
docs[[1]]
</code></p>

<p><code>
## diamond shamrock (dia) cuts crude prices
## new york, feb
## diamond shamrock corp said
## effective today   cut  contract prices  crude oil
## . dlrs  barrel.
##      reduction brings  posted price  west texas
## intermediate  . dlrs  barrel,  copany said.
##     " price reduction today  made   light  falling
## oil product prices   weak crude oil market,"  company
## spokeswoman said.
##     diamond   latest   line  u.s. oil companies
##  cut  contract,  posted, prices   last two days
## citing weak oil markets.
##  reuter
</code></p>

<h4 id="section-6">6. 去除标点</h4>

<p><code>r
docs &lt;- tm_map(docs, removePunctuation)
docs[[1]]
</code></p>

<p><code>
## diamond shamrock dia cuts crude prices
## new york feb
## diamond shamrock corp said
## effective today   cut  contract prices  crude oil
##  dlrs  barrel
##      reduction brings  posted price  west texas
## intermediate   dlrs  barrel  copany said
##      price reduction today  made   light  falling
## oil product prices   weak crude oil market  company
## spokeswoman said
##     diamond   latest   line  us oil companies
##  cut  contract  posted prices   last two days
## citing weak oil markets
##  reuter
</code></p>

<h4 id="section-7">7. 去除多余的空格</h4>

<p><code>r
docs &lt;- tm_map(docs, stripWhitespace)
docs[[1]]
</code></p>

<p><code>
## diamond shamrock dia cuts crude prices
## new york feb
## diamond shamrock corp said effective today cut contract prices crude oil dlrs barrel reduction brings posted price west texas intermediate dlrs barrel copany said price reduction today made light falling oil product prices weak crude oil market company spokeswoman said diamond latest line us oil companies cut contract posted prices last two days citing weak oil markets reuter
</code></p>

<h4 id="stemming">8. Stemming(词干化)</h4>

<p>首先介绍一下什么是Stemming，我们知道在英文中一个单词会存在很多形式，比如说复数形式、过去分词等等。但其实它们外表看起来虽不一样，但实际上是一样的。所以在处理分析的时候，就需要将这些单词都转换成其本身。在R中可以使用<code>SnowballC</code>这个包来处理Stemming，举个例子：</p>

<p><code>r
require(SnowballC)
</code></p>

<p><code>
## Loading required package: SnowballC
</code></p>

<p><code>r
exam &lt;- c("prices, price, doing")
stemDocument(exam)
</code></p>

<p><code>
## [1] "prices, price, do"
</code></p>

<p>对于我们的例子：</p>

<p><code>r
require(SnowballC)
docs &lt;- tm_map(docs, stemDocument)
docs[[1]]
</code></p>

<p><code>
## diamond shamrock dia cut crude price
## new york feb
## diamond shamrock corp said effect today cut contract price crude oil dlrs barrel reduct bring post price west texa intermedi dlrs barrel copani said price reduct today made light fall oil product price weak crude oil market compani spokeswoman said diamond latest line us oil compani cut contract post price last two day cite weak oil market reuter
</code></p>

<h3 id="section-8">4. 创建词条-文档关系矩阵</h3>
<hr />

<p>文本挖掘中，词条-文档关系矩阵是构建模型的基础，后续分析建模都是建立在这个矩阵之上的。首先来了解一下这个矩阵，举个例子：</p>

<p>我们有两篇文档，内容分别为：text mining 和 data mining and text mining。 那么对应的矩阵为：</p>

<p><code>r
d.Exam &lt;- c("text mining", "data mining and text mining")
doc.Exam &lt;- Corpus(VectorSource(d.Exam))
dtm.Exam &lt;- DocumentTermMatrix(doc.Exam)
inspect(dtm.Exam)
</code></p>

<p><code>
## A document-term matrix (2 documents, 4 terms)
##
## Non-/sparse entries: 6/2
## Sparsity           : 25%
## Maximal term length: 6
## Weighting          : term frequency (tf)
##
##     Terms
## Docs and data mining text
##    1   0    0      1    1
##    2   1    1      2    1
</code></p>

<p>可以看到，词条-文档关系矩阵其实就是将文档作为列，词条作为行，矩阵的每个位置就是对应的词条在对应的文档中出现的次数。</p>

<p>对于我们的例子，可以这样来生产词条-文档矩阵：</p>

<p><code>r
dtm &lt;- DocumentTermMatrix(docs)
inspect(dtm[1:5, 1:10])
</code></p>

<p><code>
## A document-term matrix (5 documents, 10 terms)
##
## Non-/sparse entries: 1/49
## Sparsity           : 98%
## Maximal term length: 6
## Weighting          : term frequency (tf)
##
##      Terms
## Docs  abdul abil abl abroad abu accept accord across activ add
##   127     0    0   0      0   0      0      0      0     0   0
##   144     0    2   0      0   0      0      0      0     0   0
##   191     0    0   0      0   0      0      0      0     0   0
##   194     0    0   0      0   0      0      0      0     0   0
##   211     0    0   0      0   0      0      0      0     0   0
</code></p>

<p>到这里，我们就已经生成了词条-文档矩阵。下一次，就来看看如何对这个矩阵进行一些操作，以及如何利用这个矩阵进行后续的建模分析。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据科学之机器学习17:因子分析2]]></title>
    <link href="http://jackycode.github.io/blog/2014/05/19/factor-analysis2/"/>
    <updated>2014-05-19T15:00:02+08:00</updated>
    <id>http://jackycode.github.io/blog/2014/05/19/factor-analysis2</id>
    <content type="html"><![CDATA[<p><img src="/images/article/article35.jpg" alt="article 35" />
<!-- more --></p>

<p>图片来源于<a href="http://software.ssri.co.jp/statweb2/column/column0811.html">网址</a></p>

<p><em>“文章原创，转载请注明出处”</em></p>

<hr />

<p>这两天来了个同学，大家聚了聚，我也乘机休息了两天（好奢侈！）。这两天属于什么都没有写，就翻看了两本书。一本是二月河的<a href="http://www.amazon.cn/gp/product/B0032K0X6Q/ref=olp_product_details?ie=UTF8&amp;me=&amp;seller=">康熙大帝</a>，另外一本是<a href="http://www.ituring.com.cn/book/894">推荐系统实践</a>，这本书的电子版，图灵正在打折，有兴趣可以买本看看。</p>

<hr />

<p>好了，不废话了，下面就接着上一篇讲的继续！上一篇简单介绍了因子分析的一些概念，以及最基础的因子模型：<strong>正交因子模型</strong>。那么这一篇，就来说说正交因子模型的<strong>参数估计问题</strong>。</p>

<p>对于一组p维样本，有n个观测值：<script type="math/tex">x_1, x_2, \dots, x_n</script>，则其均值和协方差矩阵可以使用样本均值和样本协方差矩阵来估计：</p>

<script type="math/tex; mode=display"> \hat{\mu} = \overline{x} = \frac{1}{n} {\sum_{i=1}^{n} x_i} </script>

<script type="math/tex; mode=display"> \hat{\Sigma} = S = \frac{1}{n-1} {\sum_{i=1}^{n} (x_i-\overline{x})(x_i-\overline{x})'} </script>

<p>在因子模型中，需要估计的有两个参数：<strong>因子载荷矩阵</strong><script type="math/tex">A=(a_{ij}:p \times m)</script>以及<strong>特殊方差矩阵</strong><script type="math/tex">D = diag(\sigma_1^2, \sigma_2^2, \dots, \sigma_p^2)</script>。</p>

<hr />

<h4 id="section">1. 主成分法</h4>
<hr />

<p>主成分法的思想取自于主成分分析，即是取出前m个成分作为主成分，然后以此来得到因子载荷矩阵的估计；然后再以协方差阵和因子载荷矩阵为条件，直接推出特殊方差矩阵。具体如下：</p>

<ol>
  <li>求出协方差矩阵<script type="math/tex">S</script>的特征值：<script type="math/tex">\hat{\lambda}_1 \geqslant \hat{\lambda}_2 \geqslant \dots \geqslant \hat{\lambda}_p \geqslant 0</script>，其对应的特征向量为：<script type="math/tex">\hat{t}_1, \hat{t}_2, \dots, \hat{t}_p</script>。</li>
  <li>选一个较小因子数<script type="math/tex">m</script>，并且使得前m项累计贡献率<script type="math/tex">\frac{\sum_{i=1}^{m} \hat{\lambda}_i}{\sum_{i=1}^{p} \hat{\lambda}_i} </script>高于设定值。</li>
  <li>将协方差矩阵<script type="math/tex">S</script>做这样的近似：<script type="math/tex">S = \sum_{i=1}^{m} \hat{\lambda}_i + \sum_{i=m+1}^{p} \hat{\lambda}_i \approx \sum_{i=1}^{m} \hat{\lambda}_i + \hat{D} := \hat{A}\hat{A}' + \hat{D} </script></li>
</ol>

<p>其中，<script type="math/tex">A = (\sqrt{\hat{\lambda}_1}t_1, \sqrt{\hat{\lambda}_2}t_2, \dots, \sqrt{\hat{\lambda}_m}t_m) </script>,<script type="math/tex">\hat{D} = diag(\hat{\sigma}_1^2, \hat{\sigma}_2^2, \dots, \hat{\sigma}_p^2) </script>,<script type="math/tex">\hat{\sigma}_i^2 = s_{ii} - \sum_{j=1}^{m} \hat{a}_{ij}^2 </script></p>

<p>从上述的过程来看，我们是使用了一种近似的方法估计出了<script type="math/tex">A</script>和<script type="math/tex">D</script>，那么这就有一个<strong>残差矩阵</strong><script type="math/tex">S - (\hat{A}\hat{A}' + \hat{D}) </script>，显然这个矩阵的对角线元素为0。既然是一种近似，那么，如果这个残差矩阵的非对角线元素都非常小的时候，我们就可以认为取<script type="math/tex">m</script>个因子的模型就可以很好地解释或者是拟合原始的数据了。</p>

<hr />

<h4 id="section-1">2. 主因子法</h4>
<hr />

<p>对于因子模型，我们先对原始向量进行标准化，则有：<script type="math/tex"> R = AA' + D</script>。取<strong>约相关矩阵</strong><script type="math/tex">R^* = R - D = AA'</script>，假设特殊方差<script type="math/tex">\sigma_i^2</script>的一个估计值<script type="math/tex">\hat{\sigma}^2</script>为初始估计，则有约相关矩阵的估计值为：</p>

<p><img src="/images/a35/eq2_1.png" alt="" /></p>

<p>其中<script type="math/tex">\hat{R}</script>为样本相关矩阵，<script type="math/tex">\hat{D} = diag(\hat{\sigma^2_1},\hat{\sigma_2^2}, \dots, \hat{\sigma_p^2}) </script>, <script type="math/tex">\hat{h_i^2} = 1 - \hat{\sigma_i^2} </script>为<script type="math/tex">h_i^2</script>的初始估计。</p>

<p>计算<script type="math/tex">\hat{R}^*</script>的特征值，取足够小，但累计贡献率达到要求的m：<script type="math/tex">\hat{\lambda^*_1} \geqslant \hat{\lambda^*_2} \geqslant \dots \geqslant \hat{\lambda^*_m} > 0 </script>，其对应的特征向量为：<script type="math/tex">\hat{t^*_1}, \hat{t^*_2}, \dots, \hat{t^*_m}</script>，则得到 <script type="math/tex">A</script> 的估计值：</p>

<script type="math/tex; mode=display"> \hat{A} = (\sqrt{\hat{\lambda^*_1}}t^*_1, \sqrt{\hat{\lambda^*_2}}t^*_2, \dots, \sqrt{\hat{\lambda^*_m}}t^*_m ) </script>

<p>那么<script type="math/tex">\sigma^2_i</script>的最终估计为： <script type="math/tex"> \hat{\sigma_i^2} = 1-\hat{h_i^2} = 1 - \sum_{j=1}^{m} \hat{a_{ij}^2} </script>。</p>

<p>可以看到，这是一个可以迭代的过程，我们可以一直迭代，直到结果达到稳定为止！从过程来看，这里其实也是利用了主成分，因而，主因子法也是主成分法的一种修正！</p>

<p>那么接下来的问题就是，这个特殊方差<script type="math/tex">\sigma^2_i</script>的初始估计值应该如何取呢？最常用的取法：<script type="math/tex"> \hat{\sigma_i^2} = 1/r^{ii} </script>, 其中<script type="math/tex"> r^{ii} </script>为<script type="math/tex">\hat{R}^{-1}</script>对角线元素的第<script type="math/tex">i</script>个。</p>

<hr />

<h4 id="section-2">3. 极大似然法</h4>
<hr />

<p>使用极大似然估计，那么就肯定需要使用样本的分布，这里我们假定公共因子<script type="math/tex">f \sim N_m(0, I) </script>，特殊因子<script type="math/tex"> \varepsilon \sim N_p(0, D) </script>，并且相互独立！这里的假设其实就是来源于模型的正交性假设，只不过是将正交性假设进一步限定，假设它们都是属于多元正态分布！</p>

<p>有了上述假设，通过模型就可以知道<script type="math/tex">x \sim N_p(\mu, \Sigma) </script>，有了这个就可以计算样本的似然函数了，这里涉及到较为复杂的矩阵计算，不想多说，有兴趣的话可以查找一些资料；或者学习一下线性模型中关于矩阵求导的知识，然后自己推导一下。</p>

<p>一般情况下，极大似然法使用得并不太多，因为这个方法是算不出显式解的，在没有限制条件的情况下，解也并不唯一确定！但是如果是在因子分部可以明显知道的情况下，使用这个方法就比较好了！</p>

<hr />

<h3 id="section-3">总结</h3>
<hr />

<p>到这边，对于基础的因子模型就介绍结束了。回顾一下，主要就是介绍了正交因子模型以及它的参数估计问题。但是，到这里，我们还没有说到模型中的公共因子如何解释这个问题！对于这个问题的解释，通常结合实际的问题，需要一定的专业知识和经验，然后才能给每个公共因子给出一个实际意义。而且，公共因子的解释，在很大程度上也依赖于因子模型中因子载荷矩阵的元素结构！这个时候就会牵扯出因子分析中其它的一些问题：<strong>因子旋转</strong>和<strong>因子得分</strong>。因为这两个问题涉及到一些比较复杂的数学知识，我不能够在清减数学的情况下说好它，如果单说怎么用，我觉得没有必要，所以暂时并不打算介绍这两个问题。有兴趣的，可以翻阅一些多元统计的书籍，一般都会有讲。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据科学之机器学习16:因子分析1]]></title>
    <link href="http://jackycode.github.io/blog/2014/05/14/factor-analysis1/"/>
    <updated>2014-05-14T16:05:45+08:00</updated>
    <id>http://jackycode.github.io/blog/2014/05/14/factor-analysis1</id>
    <content type="html"><![CDATA[<p><img src="/images/article/article34.jpg" alt="article 34" />
<!-- more --></p>

<p>图片来源于<a href="http://software.ssri.co.jp/statweb2/column/column0811.html">网址</a></p>

<p><em>“文章原创，转载请注明出处”</em></p>

<hr />

<p>前一篇介绍的主成分分析(PCA)，是一种降维技术；这一篇介绍的因子分析也是一种降维的方法，不仅如此，还可以将因子分析看作是主成分分析的一种推广和发展。与之主成分分析相比较，因子分析更为灵活，对变量降维后的解释能够更加清楚。</p>

<p>但因子分析和主成分分析有非常多的不同点。</p>

<ol>
  <li>主成分分析不能作为一个模型来描述，主成分是观测变量的线性组合；</li>
  <li>因子分析需要构造因子模型，观测的原始变量是因子的线性组合。</li>
</ol>

<hr />

<h4 id="section">初窥</h4>
<hr />

<p>在介绍因子模型之前，可以先看看这个因子分析到底是要干什么，以及是怎么干的！</p>

<p>在二维空间中，主成分分析，它想做的是寻找一组新的变量<script type="math/tex">y_1,y_2</script>，用它去替代原来的变量<script type="math/tex">x_1,x_2</script>，并且满足<script type="math/tex">y_1</script>和<script type="math/tex">y_2</script>这两个变量都是<script type="math/tex">x_1,x_2</script>两个变量的线性组合！即：</p>

<p><img src="/images/a34/eq1.jpg" alt="" /></p>

<p>而在因子模型中，我们需要做的跟此不同。我们需要找到一组潜在变量(不可观测)，用这组潜在变量的线性组合去表示原始变量<script type="math/tex">x_1,x_2</script>。这里假设有1个潜在变量<script type="math/tex">f_1</script>，那么因子模型可以描述成：</p>

<p><img src="/images/a34/eq2.png" alt="" /></p>

<p>其中，<script type="math/tex">f_1</script>就是因子，称为<strong>公共因子</strong>；<script type="math/tex">a_{ij}</script>称之为变量<script type="math/tex">x_i</script>在因子<script type="math/tex">f_j</script>上的<strong>载荷</strong>；<script type="math/tex">\mu_i</script>是<script type="math/tex">x_i</script>的均值；<script type="math/tex">\varepsilon_i</script>为特殊因子，即不能被公共因子解释的部分。</p>

<hr />

<h4 id="section-1">正交因子模型</h4>
<hr />

<p>首先看看最基础的因子模型，就是正交假设下的因子模型：</p>

<p><img src="/images/a34/eq3.png" alt="" /></p>

<p>在给出假定之前，我们先将上面式子转换成矩阵形式：</p>

<script type="math/tex; mode=display"> x = \mu + Af + \varepsilon </script>

<p>其中，<script type="math/tex">x = (x_1, x_2, \dots, x_p)'</script>，<script type="math/tex">\mu = (\mu_1, \mu_2, \dots, \mu_p)'</script>为均值向量，<script type="math/tex">\varepsilon = (\varepsilon_1, \varepsilon_2, \dots, \varepsilon_p)'</script>为特殊因子向量, <script type="math/tex">f = (f_1, f_2, \dots, f_p)'</script>为公共因子向量，<script type="math/tex"> A = (a_{ij}):p \times m </script>为载荷矩阵。那么我们就可以给出如下的正交假设：</p>

<p><img src="/images/a34/eq4.png" alt="" /></p>

<p>在这样的假定下，我们首先来计算一下，原始变量<script type="math/tex">x</script>的协方差：</p>

<script type="math/tex; mode=display"> \Sigma = V(x) = V(Af+\varepsilon) = Cov(Af+\varepsilon,Af+\varepsilon) </script>

<p>又：<script type="math/tex">Cov(Af+\varepsilon,Af+\varepsilon)=AV(f)A'+ACov(f,\varepsilon)+Cov(\varepsilon,f)A'+V(\varepsilon)</script></p>

<p>由于<script type="math/tex">V(f) = I, Cov(f, \varepsilon) = Cov(\varepsilon, f) = 0</script>，所以：</p>

<script type="math/tex; mode=display"> \Sigma = AA' + V(\varepsilon) = AA' + D </script>

<p><strong>显然，我们要处理正交因子模型，最重要的就是求解<script type="math/tex">A,D</script>的估计值，那么这里就给出了这两个量与原始变量的协方差矩阵间的关系。</strong></p>

<p><strong>那么我们开始所说的，因子分析也是一种降维手段体现在哪里呢？</strong>这个就体现在，公共因子的数量上，当公共因子的数量少于原始变量的数量时，使用因子去解释原始变量就达到了一种降维的目的！</p>

<hr />

<p><strong><em>载荷矩阵</em></strong></p>

<p>显然，载荷矩阵<script type="math/tex">A</script>是我们关心的一个重点。首先，我们想弄明白<script type="math/tex">A</script>中的元素<script type="math/tex">a_{ij}</script>是否有什么具体的含义：</p>

<script type="math/tex; mode=display">Cov(x_i,f_j)=Cov(\sum_{k=1}^{m}a_{ik}f_k + \varepsilon_i, f_j) =a_{ij}Cov(f_j,f_j) = a_{ij} </script>

<p>那么可以看到，<script type="math/tex">a_{ij}</script>是<script type="math/tex">x_i</script>和<script type="math/tex">f_j</script>之间的协方差函数。</p>

<p>经过上面的计算，我们容易得到：</p>

<script type="math/tex; mode=display">V(x_i) = a_{i1}^2 + a_{i2}^2 + \dots + a_{1m}^2 + V(\varepsilon_i)</script>

<p>记<script type="math/tex">h_i^2 = \sum_{j=1}^{m}a_{ij}^2</script>，那么上式可转化为：</p>

<script type="math/tex; mode=display"> (V(x_i) =) \sigma_{ii} = h_i^2 + \sigma_i^2, i=1,2,\dots,p</script>

<p>这样就将<script type="math/tex">x_i</script>的方差进行了一个分解，一部分由公共因子解释，即<script type="math/tex">h_i^2</script>，称为<strong>共性方差</strong>；另一部分由特殊因子解释，即<script type="math/tex">\sigma_i^2</script>，称为<strong>特殊方差</strong>。</p>

<hr />

<p>至此，因子分析的基础模型就介绍完了，下面剩下的就是如何去进行参数的估计，这一般有三种方法：主成分法、主因子法以及极大似然法。下一篇，我们就来详细说说因子分析的参数估计问题。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据科学之机器学习15: 主成分分析]]></title>
    <link href="http://jackycode.github.io/blog/2014/05/11/principal-components/"/>
    <updated>2014-05-11T11:35:10+08:00</updated>
    <id>http://jackycode.github.io/blog/2014/05/11/principal-components</id>
    <content type="html"><![CDATA[<p><img src="/images/article/article33.jpg" alt="article 33" />
<!-- more --></p>

<p>图片为：本文实例数据得到的，前两个主成分的散点图！</p>

<p><em>“文章原创，转载请注明出处”</em></p>

<hr />

<p>在之前<a href="http://jackycode.github.io/blog/2014/04/02/linear-regression3/">线性回归3</a>提到多重共线性问题，当时说了一些解决这个问题的办法，其中一种就是今天要说的<strong>主成分分析</strong>。</p>

<p><strong>主成分分析</strong>，Principal Components Analysis，简称PCA，是变量选择的一种方法。其一般的目的就是：变量的降维和主成分的解释！当主成分用于聚类或者回归，这个时候就是在做变量的降维；而当用来分析变量，尤其是使用前两个主成分进行散点图的绘制时，此时就是在对变量利用主成分做出一些解释。在了解主成分分析的原理之后，相信对这两个目的就可以很容易直观的理解了！</p>

<hr />

<h4 id="section">一、原理初窥</h4>
<hr />

<p>在用数学公式和概率统计知识推导其原理之前，不妨先直观地看看主成分分析到底是要干嘛，以及大致是怎么干的！</p>

<p>我们就用两个变量来说这个问题，变量分别记作<script type="math/tex">x_1,x_2</script>。那么，我们先画个散点图吧，也许它们的散点图是这个样子的：</p>

<p><img src="/images/a33/images1.jpg" alt="" /></p>

<p>我们可以看到，这两个变量明显呈现一种线性关系，如果在做线性回归时，将这两个变量都用作自变量，然后对某一个因变量进行线性拟合，那必定会存在一些问题。那么主成分分析是要做什么呢？其实主成分分析就是要寻找变量<script type="math/tex">y_1,y_2</script>去替代<script type="math/tex">x_1,x_2</script>，而且满足<script type="math/tex">y_1,y_2</script>几乎不相关，同时<script type="math/tex">y_1,y_2</script>能够保留<script type="math/tex">x_1,x_2</script>所包含的信息。</p>

<p>那么主成分分析是如何做的呢？这个时候就需要考虑旋转坐标轴，当我们像下图那样旋转过坐标轴之后，上面提出的要求就得到了实现。</p>

<p><img src="/images/a33/images2.jpg" alt="" /></p>

<p>从这张图我们就可以看出，数据投影到<script type="math/tex">y_1,y_2</script>两轴后，数据基本不相关，而且在<script type="math/tex">y_1</script>轴就保留了原本数据的大部分信息，<script type="math/tex">y_2</script>保留了数据的另外一部分信息。由此可见，数据越是集中在<script type="math/tex">y_1</script>轴两侧，数据映射到<script type="math/tex">y_1</script>轴后保留的信息就越多，而<script type="math/tex">y_2</script>就越少。当<script type="math/tex">y_2</script>含有的信息非常少，少到接近于0时，那么此时就到达了变量选择的目的，因为此时只要保留<script type="math/tex">y_1</script>就可以了。</p>

<hr />

<h4 id="section-1">二、原理</h4>
<hr />

<p>我们将数据映射到<script type="math/tex">y_1,y_2</script>轴，其实就是将原数据做个线性变换。利用上面的内容举个简单地例子就是：</p>

<p><img align="center" src="http://jackycode.github.io/images/a33/eq1.jpg" /></p>

<p>其中的系数满足：<script type="math/tex">a_{11}^2 + a_{21}^2=1,a_{12}^2 + a_{22}^2=1</script>。这样就可以成功地将数据投影到<script type="math/tex">y_1,y_2</script>轴。这里我们考虑更一般的情况，考虑<script type="math/tex">p</script>维的情况：</p>

<p><img align="center" src="http://jackycode.github.io/images/a33/eq2.jpg" /></p>

<p>其中<script type="math/tex">a_i=(a_{1i},a_{2i},\dots,a_{pi})', i=1,2,\dots,p</script>，且满足<script type="math/tex">a_i'a_1=1</script>。</p>

<p>下面要考虑的就是，如何选择<script type="math/tex">a_1</script>，使得<script type="math/tex">V(y_1)</script>到达最大，找到之后，<script type="math/tex">y_1</script>就是<strong>第一主成分</strong>。</p>

<p>首先，<script type="math/tex">V(y_1)=a_1' \Sigma a_1</script>，其中<script type="math/tex">\Sigma=V(x)</script>为协方差矩阵。我们知道<script type="math/tex">\Sigma</script>是非负定的，那么其所有的特征值必定都是大于等于0的，我们可以排个序：<script type="math/tex">\lambda _{ 1 }\geqslant \lambda _{ 2 }\geqslant \dots \geqslant \lambda_p \geqslant 0</script>，其对应的特征向量记为：<script type="math/tex">t_1, t_2, \dots, t_p</script>，显然这些特征向量是相互正交的。记<script type="math/tex">T=(t_1, t_2, \dots, t_p)=(t_{ik}), \Lambda=diag(\lambda_1,\lambda_2,\dots,\lambda_p)</script>。</p>

<p>那么根据谱分解就有：<script type="math/tex">\Sigma=T \Lambda T'=\sum_{i=1}^{p}\lambda_it_it_i'</script>。那么带入到<script type="math/tex">V(y_1)</script>中就有：</p>

<script type="math/tex; mode=display">V(y_1)=\sum_{i=1}^{p} \lambda_i a_1' t_it_i' a_1 = \sum_{i=1}^{p} \lambda_i(a_1't_i)^2</script>

<p>由于特征值中<script type="math/tex">\lambda_1</script>是最大的，那么就有：</p>

<script type="math/tex; mode=display">V(y_1) \leqslant \lambda_1 \sum_{i=1}^{p} (a_1't_i)^2 = \lambda_1 \sum_{i=1}^{p} {a_1't_it_i'a_1} = \lambda_1 a_1' TT'a_1 = \lambda_1</script>

<p>可以看到最终的结果是：<script type="math/tex">V(y_1) \leqslant \lambda_1</script>。那么什么时候取等号呢？取<script type="math/tex">a_1 = t_1</script>，则有：</p>

<script type="math/tex; mode=display">t_1'\Sigma t_1 = t_1' (\lambda_1t_1) = \lambda_1</script>

<p>到止为止，就可以看到。当<script type="math/tex">y_1=t_1'x</script>时就有其<script type="math/tex">V(y_1)</script>达到最大，为<script type="math/tex">\lambda_1</script>。那么此时<script type="math/tex">y_1=t_1'x</script>就是该数据第一主成分。</p>

<p>同理可以求解第二主成分直至最后。<strong>但是，在求解第二第三主成分的时候，需要注意一个新的问题：主成分之间不相关，即<script type="math/tex">Cov(y_i,y_k)=0,i \neq k</script></strong>，如何证明非常简单，我就不说了，自己动动手吧。</p>

<hr />

<h4 id="section-2">三、具体实例</h4>
<hr />

<p>我们使用R语言来做个小例子：</p>

<p>``` r
# 构造一个数据集
set.seed(10)
x1 &lt;- seq(1, 50, 2) + rnorm(25, mean=1, sd=1)
x2 &lt;- 2*x1 + rnorm(25, mean=1, sd=1)
x3 &lt;- x1/2 + x2 + rnorm(25, mean=1, sd=1)
x &lt;- data.frame(x1=x1, x2=x2, x3=x3)</p>

<h1 id="section-3">计算协方差矩阵</h1>
<p>Sig &lt;- cov(x)</p>

<h1 id="section-4">计算特征值和特征向量</h1>
<p>eigen(Sig)
```
得到结果如下：</p>

<p>``` r
$values
[1] 2381.3724526    0.3681085    0.1165201</p>

<p>$vectors
           [,1]       [,2]        [,3]
[1,] -0.2982259 -0.4601189  0.83627265
[2,] -0.6002191 -0.5908325 -0.53912331
[3,] -0.7421579  0.6627273  0.09997061
```</p>

<p>得到了特征值为：<script type="math/tex">\lambda_1=238.372, \lambda_2=0.368, \lambda_3=0.11652</script>，可以看到第一主成分<script type="math/tex">y_1=t_1'x=-0.298x_1-0.600x_2-0.742x_3</script>的特征值<script type="math/tex">\lambda_1</script>的值远大于其余的(由于数据构造时就是以<script type="math/tex">x_1</script>为底的)。说明第一主成分能够解释数据的大部分信息，那么如何衡量呢？</p>

<p>这时候就需要使用到<strong>贡献率</strong>这个概念，某一个主成分<script type="math/tex">y_i</script>的贡献率定义为：<script type="math/tex">\frac{\lambda_i}{\sum_{i=1}^{p} \lambda_i}</script>。</p>

<p>贡献率越大说明这个主成分能够解释数据的信息就越多，在具体的问题中，还常常用到一个概念，就是<strong>累积贡献率</strong>。前<script type="math/tex">k</script>个主成分的累计贡献率就是：<script type="math/tex">\frac{\sum_{i=1}^{k} \lambda_i}{\sum_{i=1}^{p} \lambda_i}</script>。实际中，当前<script type="math/tex">k</script>个主成分的累积贡献率达到某个临界值，比如<script type="math/tex">80\%</script>，就选择前<script type="math/tex">k</script>个主成分进行下一步操作(比如说聚类，回归或者单纯地做分析等等)</p>

<h4 id="section-5">四、基于相关矩阵</h4>
<hr />

<p>考虑这样两种情况：各个变量的单位不全相同，也就是数据的量纲不同；各变量之间的单位相同，但是变量的方差较大，也就是数值大小相差较大。那么这个时候，如果从协方差矩阵出发求解主成分，就显得不大合适了。</p>

<p>在之前的文章中提到过，当所有的变量都进行了标准化之后，协方差矩阵<script type="math/tex">\Sigma</script>就转换成了相关矩阵<script type="math/tex">R</script>！</p>

<p>那么，剩下的求解过程就与上面相同了，这里不再叙述。需要指出的是，标准化与否，所得到的结果可能会有很大的不同，所以，判断一批数据是否需要标准化是很有必要的！</p>

<h4 id="r">五、R语言实现</h4>
<hr />

<p>主成分分析的R语言实现比较简单，可以直接使用<code>eigen()</code>函数求出特征值特征向量。当然也有自带的函数：<code>princomp()</code>以及<code>psych</code>包中的<code>principal()</code>函数，可以自己查找一下帮助文档，这里就不做介绍了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据科学之机器学习14: 关联分析之apriori算法]]></title>
    <link href="http://jackycode.github.io/blog/2014/05/07/apriori/"/>
    <updated>2014-05-07T17:00:48+08:00</updated>
    <id>http://jackycode.github.io/blog/2014/05/07/apriori</id>
    <content type="html"><![CDATA[<p><img src="/images/article/article31.jpg" alt="article 31" />
<!-- more --></p>

<p><em>“文章原创，转载请注明出处”</em></p>

<hr />

<p>在上一篇中，我们介绍了关联分析相关的概念，这一节来看看如何使用Apriori算法去寻找满足条件的项集。</p>

<p>首先回顾一个概念，<strong>一个项集的支持度</strong>就是数据集中该项集所占的比例。Apriori算法就是用于寻找数据集中，支持度和可信度超过某一给定值的项集和关联规则。</p>

<hr />

<h4 id="section">一、原理</h4>
<hr />

<p>在介绍算法之前，首先了解一个集合论中的性质定理：集合的向下封闭性。</p>

<p>我们通过一个例子来看看这个定理，见下图：</p>

<p><img src="/images/a31/apriori_1.jpg" alt="" /></p>

<p>集合的向下封闭性，在这边解释的话，也就是说，<strong>如果一个项集的支持度低于某一个值，那么该项集超集的支持度也必定低于这个值。如果一个项集的支持度高于某一个值，那么该项集子集的支持度也必定高于某一个值。</strong></p>

<p><strong>超集</strong>：就是指包含这个集合中所以元素的集合（不包括自身），比如集合ABC就是集合AB的超集。</p>

<p>那么这个定理放在上一个图当中，就有这样的含义：</p>

<p><img src="/images/a31/apriori_2.jpg" alt="" /></p>

<hr />

<h4 id="section-1">二、算法构成</h4>
<hr />

<p>有了上面这个原理，那么就可以利用这个原理去减少我们寻找频繁集的计算量。因为，只要我们找到一个项集，其支持度低于给定的值，那么这个项集的所有超集就可以直接忽略不计了。如上图，项集A的支持度低于指定的值，那么其超集就都不用再考虑了。</p>

<p><strong>Apriori算法由两部分构成：</strong></p>

<ol>
  <li>找到满足最小支持度的项集；</li>
  <li>找到可信度超过最小可信度的关联规则。</li>
</ol>

<p>下面，我们一个一个地解决：</p>

<hr />

<h5 id="section-2">2.1. 寻找频繁项集</h5>
<hr />

<p>利用上面所讲的原理，我们来整理一下这个步骤的流程：</p>

<ol>
  <li>从数据集中构造集合C1，C1满足：大小为1的所有候选项集的集合，例如上图中的：C1 = {A, B, C};</li>
  <li>计算C1中所有项集（单元素项集）是否满足最小支持度，满足的项集构成集合L1，例如上图中的：L1 = {B, C};</li>
  <li>利用L1生成新的候选项集C2，C2满足：大小为2的所有候选项集的集合，例如上图中得：C2 = {BC};</li>
  <li>计算C2中所有项集（双元素项集）是否满足最小支持度，满足的项集构成集合L2；</li>
  <li>重复直到Lk中得元素个数为1。</li>
</ol>

<hr />

<h5 id="section-3">2.2. 寻找关联规则</h5>
<hr />

<p>在得到频繁项集之后，要寻找关联规则就容易多了。可以直接从频繁项集中构造初始的关联规则，计算该关联规则的可信度，然后与给定的最小可信度作比较，若值大于最小可信度，则记录该关联规则。</p>

<p>在实际编程时，需要注意使用<strong>集合的向下封闭性</strong>！！！想想看，在关联规则中，这个性质应该怎样去实现？(可以到Machine Learning in Action中找答案！)</p>

<h4 id="r">三、R语言实现</h4>

<h5 id="section-4">1. 使用自带的程序</h5>

<p>在R语言的<code>arules</code>这个包里面，提供了一个实现Apriori算法的函数：<code>apriori()</code>：</p>

<p><code>r
# 构造数据集
dataSet &lt;- matrix(0, 5, 3)
rownames(dataSet) &lt;- paste("item", 1:5, sep='')
colnames(dataSet) &lt;- c("A", "B", "C")
dataSet[1,] &lt;- c(1, 1, 0)
dataSet[2,] &lt;- c(1, 0, 1)
dataSet[3,] &lt;- c(1, 0, 1)
dataSet[4,] &lt;- c(1, 1, 1)
dataSet[5,] &lt;- c(0, 1, 1)
dataSet
# 转换数据格式(可以?apriori查看数据格式)
dataSet_class &lt;- as(dataSet,"transactions")
# 构造频繁项集
rules&lt;-apriori(dataSet_class,parameter=list(supp=0.5,conf=0.6,target="rules"))
# 查看结果
summary(rules)
# 构造关联规则
inspect(rules)
</code></p>

<h5 id="section-5">2. 自定义函数解决</h5>

<p>相对而言，Apriori算法的函数比较难以编写，原因可想而知，肯定是因为数据结构的问题！但是也只是比其他函数难编一点，毕竟其自带的数据结构功能还是非常强大的。我在<a href="/datascience">我的项目</a>中给出的一种编写方式，是利用R语言的list来实现的。不过，我想，利用Matrix或者data.frame，当然如果你还懂<code>data.table</code>的话，那么肯定也是可以编写的，而且我想应该会比用list简单！(没有亲手编写，只是猜想！)</p>

<p>详见<a href="/datascience">我的项目</a></p>
]]></content>
  </entry>
  
</feed>
