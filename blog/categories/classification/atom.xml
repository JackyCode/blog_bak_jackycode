<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Classification | Jacky and MSC]]></title>
  <link href="http://jackycode.github.io/blog/categories/classification/atom.xml" rel="self"/>
  <link href="http://jackycode.github.io/"/>
  <updated>2014-04-06T14:09:03+08:00</updated>
  <id>http://jackycode.github.io/</id>
  <author>
    <name><![CDATA[Jacky Code]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[数据科学之机器学习5：分类之k-近邻算法]]></title>
    <link href="http://jackycode.github.io/blog/2014/04/05/knn/"/>
    <updated>2014-04-05T19:59:29+08:00</updated>
    <id>http://jackycode.github.io/blog/2014/04/05/knn</id>
    <content type="html"><![CDATA[<p><img src="/images/artical/artical19.jpg" alt="artical 19" />
<!-- more --></p>

<p><em>“文章原创，转载请注明出处”</em></p>

<hr />

<h4 id="section">基本思想</h4>
<hr />

<p>kNN，k-Nearest Neighbor algorithm，也就这边的k-近邻算法，是数据挖掘十大算法之一，是一个比较简单的分类方法。</p>

<p>其基本的思想是：对于一个输入样本（未知分类的样本），考虑其与测试样本中与之距离最近（特征最相似）的k个样本，用这k个样本中出现最多的分类作为输入样本的分类。</p>

<h4 id="section-1">具体流程</h4>
<hr />

<p>对于输入样本中的每一个点，进行以下操作：</p>

<ol>
  <li>计算点与测试样本中点的距离；</li>
  <li>取出与当前点距离最小的k个点；</li>
  <li>确定k个点的分类，计算各个分类的频数；</li>
  <li>返回频数最高的类别，作为该输入点的预测分类。</li>
</ol>

<h4 id="section-2">距离的计算</h4>
<hr />

<p>上面一直在说，计算输入样本中点与测试样本中点之间的距离，那么这个距离应该怎么计算呢？这个距离一般就是使用欧式距离：</p>

<script type="math/tex; mode=display"> d = \sqrt{(x - y)^T(x - y)} </script>

<p>其中<script type="math/tex">x^T=[x_1, x_2,\dots,x_n], y^T=[y_1,y_2,\dots,y_n]</script>。二维的表示就是：</p>

<script type="math/tex; mode=display"> d = \sqrt{(x - y)^T(x - y)} = \sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2} </script>

<h4 id="r">R语言实现</h4>
<hr />

<p>见<a href="https://github.com/JackyCode/Data_Science/tree/master/kNN">我的github</a>。</p>
]]></content>
  </entry>
  
</feed>
