<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: TextMining | Jacky and MSC]]></title>
  <link href="http://jackycode.github.io/blog/categories/textmining/atom.xml" rel="self"/>
  <link href="http://jackycode.github.io/"/>
  <updated>2014-08-18T15:39:17+08:00</updated>
  <id>http://jackycode.github.io/</id>
  <author>
    <name><![CDATA[Jacky Code]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[数据科学20：文本挖掘2]]></title>
    <link href="http://jackycode.github.io/blog/2014/06/26/text-mining2/"/>
    <updated>2014-06-26T15:02:09+08:00</updated>
    <id>http://jackycode.github.io/blog/2014/06/26/text-mining2</id>
    <content type="html"><![CDATA[<p><img src="/images/article/article42.jpg" alt="article 42" />
<!-- more --></p>

<p>图片由本文中数据生产~</p>

<p><em>“文章原创，转载请注明出处”</em></p>

<hr />

<h2 id="section">一、对词条-文档矩阵的操作</h2>

<hr />

<p>在’tm’包中，提供了一些常用的函数，可以对得到的Document Term
Matrix进行一些操作。当然，我们也可以使用自己的方式，对该矩阵进行一些探索，比如，我们先来看看词条的频数：</p>

<h3 id="section-1">1.1 词条频数</h3>

<hr />

<p>``` r
freq &lt;- colSums(as.matrix(dtm))
length(freq)</p>

<h2 id="section-2">[1] 780</h2>
<p>```</p>

<p>如果我们想看看，哪些频数是大于等于30的，我们可以：</p>

<p>``` r
names(freq[freq &gt;= 30])</p>

<h2 id="market-mln----oil----opec---price--said">[1] “market” “mln”    “oil”    “opec”   “price”  “said”</h2>
<p>```</p>

<p>但其实，在’tm’包中有自带的函数可以解决：</p>

<p>``` r
findFreqTerms(dtm, lowfreq = 30)</p>

<h2 id="market-mln----oil----opec---price--said-1">[1] “market” “mln”    “oil”    “opec”   “price”  “said”</h2>
<p>```</p>

<p>如果得到了每个词条的频数，我们可以列一个表查看一些其它的东西：</p>

<p>``` r
ord &lt;- order(freq, decreasing = TRUE)
## 查看频数排在前十的词条及其频数
head(freq[ord], 10)</p>

<h2 id="oil---said--price---opec----mln-market-barrel---last----bpd---dlrs">oil   said  price   opec    mln market barrel   last    bpd   dlrs</h2>
<p>##     86     73     63     47     31     30     26     24     23     23</p>

<h2 id="section-3">查看频数的频数</h2>
<p>tail(table(freq), 10)</p>

<h2 id="freq">freq</h2>
<p>## 21 23 24 26 30 31 47 63 73 86
##  2  2  1  1  1  1  1  1  1  1
```</p>

<h3 id="section-4">1.2 相关性</h3>

<hr />

<p>除了词条的频数，我们大都还会对词条之间的相关性感兴趣。如何计算，其实很简单：</p>

<p>``` r
corr &lt;- cor(as.matrix(dtm))
corr[1:5, 1:5]</p>

<h2 id="abdul-----abil------abl---abroad---accept">abdul     abil      abl   abroad   accept</h2>
<p>## abdul   1.00000 -0.08812 -0.05263 -0.05263 -0.05263
## abil   -0.08812  1.00000 -0.08812  0.79309 -0.08812
## abl    -0.05263 -0.08812  1.00000 -0.05263 -0.05263
## abroad -0.05263  0.79309 -0.05263  1.00000 -0.05263
## accept -0.05263 -0.08812 -0.05263 -0.05263  1.00000</p>

<p>dim(corr)</p>

<h2 id="section-5">[1] 780 780</h2>
<p>```</p>

<p>比如我们想知道，与词条’oil’相关性超过0.8的词条有哪些：</p>

<p>``` r
op &lt;- options()
options(digits = 2)
name &lt;- setdiff(names(corr[, “oil”][corr[, “oil”] &gt; 0.8]), “oil”)
value &lt;- corr[name, “oil”]
matrix &lt;- matrix(value[order(value, decreasing = TRUE)])
rownames(matrix) = names(value)
colnames(matrix) = “oil”
matrix</p>

<h2 id="oil">oil</h2>
<p>## name 0.87
## opec 0.81
## tri  0.81
## want 0.81</p>

<p>options(op)
```</p>

<p>但其实，’tm’包中提供了现成函数：</p>

<p>``` r
findAssocs(dtm, “oil”, 0.8)</p>

<h2 id="oil-1">oil</h2>
<p>## opec 0.87
## name 0.81
## tri  0.81
## want 0.81
```</p>

<p>可以看到，这一个函数实现了上面我们那一长串的功能。<strong>但是，我觉得，提供的现成函数有好处，但还是需要自己想想如何实现这个现成的函数。这不仅对概念理解有帮助，也对程序编写以及了解别人写的函数有更加深刻的理解。</strong></p>

<h3 id="section-6">1.3 删减稀疏条目</h3>

<hr />

<p>大部分时候，Document Term
Matrix是一个很大的矩阵，而且是行数远小于列数。也就是说，这个矩阵实际上是很稀疏的，不妨来看看我们这个只有20个文档的矩阵，稀疏程度如何：</p>

<p>``` r
Sparse &lt;- length(which(matrix(dtm) == 0))
Sparse</p>

<h2 id="section-7">[1] 14030</h2>

<p>Non &lt;- length(which(matrix(dtm) != 0))
Non</p>

<h2 id="section-8">[1] 1570</h2>

<p>sprintf(“%d%%”, round(Sparse/(Non + Sparse), 2) * 100)</p>

<h2 id="section-9">[1] “90%”</h2>
<p>```</p>

<p>可以看到，矩阵中等于零的数目是14030，不为零的为1570，稀疏程度达到了90%，显然是非常稀疏的。当然，其实这个可以不用自己算的：</p>

<p>``` r
dtm</p>

<h2 id="documenttermmatrix-documents-20-terms-780">«DocumentTermMatrix (documents: 20, terms: 780)»</h2>
<p>## Non-/sparse entries: 1570/14030
## Sparsity           : 90%
## Maximal term length: 13
## Weighting          : term frequency (tf)
```</p>

<p>上面的输出，前两个就知道它的意思了。那么另外两个呢？“Maximal term
length”，顾名思义，就是最长的那个词条的长度。不妨来看一下：</p>

<p>``` r
name &lt;- colnames(as.matrix(dtm))
name.length &lt;- sapply(name, nchar)
max.name &lt;- name[name.length == max(name.length)]
max.value &lt;- name.length[max.name]
max.value</p>

<h2 id="responsibilit">responsibilit</h2>
<p>##            13
```</p>

<p>可以看到是吻合的。至于最后一个“Weighting”，是指Document Term
Matrix中的每一条目的值是如何计算的。这里用的是“term
frequency”，就是词条频率，简写为“tf”。除了这个，还有一些其它计算方法，比如：tf-idf，即term
frequency-inverse document frequency。这个以后再说。</p>

<hr />

<p><strong>回到主题：</strong>计算出了稀疏条目的比例，证实了矩阵的确是很稀疏的，那么下面就是要去删除一些条目。有些条目在很少的文档中出现，甚至只在一篇文档中出现了。一般来说，删除这样的条目不会对矩阵的信息继承带来显著的影响。</p>

<p>``` r
remove.sparseterms &lt;- function(dtm, per) {
    dtm.Matrix &lt;- as.matrix(dtm)
    term.per &lt;- apply(dtm.Matrix, 2, function(item) length(which(item == 0))/length(item))
    name &lt;- names(term.per[which(term.per &lt; per)])
    return(dtm.Matrix[, name])
}
remove.sparseterms(dtm, 0.4)</p>

<h2 id="terms">Terms</h2>
<p>## Docs  barrel oil one price reuter said
##   127      2   5   0     5      1    3
##   144      0  12   1     6      2   11
##   191      1   2   0     2      1    1
##   194      1   1   1     2      1    1
##   211      0   1   0     0      1    3
##   236      4   7   1     8      1   10
##   237      0   4   1     1      1    1
##   242      0   3   2     2      1    3
##   246      1   5   1     2      1    5
##   248      3   9   1    10      1    7
##   273      3   5   1     5      1    8
##   349      0   4   0     1      1    1
##   352      1   5   0     5      1    2
##   353      1   4   1     2      1    1
##   368      0   3   0     0      1    3
##   489      3   4   2     3      1    2
##   502      3   5   2     3      1    2
##   543      1   3   1     3      1    4
##   704      0   3   4     3      1    4
##   708      2   1   0     0      1    1
```</p>

<p>这边的计算就是：检查词条的稀疏程度是否低于给定的系数<code>per</code>，如果是，就保留该词条；如果不是，则舍弃。</p>

<p>当然，在’tm’包中也有自带的函数可以解决：</p>

<p>``` r
rsterms &lt;- removeSparseTerms(dtm, 0.4)
inspect(rsterms)</p>

<h2 id="documenttermmatrix-documents-20-terms-6">«DocumentTermMatrix (documents: 20, terms: 6)»</h2>
<p>## Non-/sparse entries: 103/17
## Sparsity           : 14%
## Maximal term length: 6
## Weighting          : term frequency (tf)
##
##      Terms
## Docs  barrel oil one price reuter said
##   127      2   5   0     5      1    3
##   144      0  12   1     6      2   11
##   191      1   2   0     2      1    1
##   194      1   1   1     2      1    1
##   211      0   1   0     0      1    3
##   236      4   7   1     8      1   10
##   237      0   4   1     1      1    1
##   242      0   3   2     2      1    3
##   246      1   5   1     2      1    5
##   248      3   9   1    10      1    7
##   273      3   5   1     5      1    8
##   349      0   4   0     1      1    1
##   352      1   5   0     5      1    2
##   353      1   4   1     2      1    1
##   368      0   3   0     0      1    3
##   489      3   4   2     3      1    2
##   502      3   5   2     3      1    2
##   543      1   3   1     3      1    4
##   704      0   3   4     3      1    4
##   708      2   1   0     0      1    1
```</p>

<p>与之前的结果相同。</p>

<h2 id="section-10">二、相关的绘图</h2>

<hr />

<p>介绍完Document Term
Matrix之后，其实已经可以开始使用模型去处理了。之前介绍过聚类、分类啊等等的内容，有了这个矩阵之后，其实都可以去做了。不过，在建立模型之前，我想先说说有关绘图的问题。</p>

<p>我们前面算了很多的量，比如频数啊、相关系数啊等等。但其实，我们大多时候需要用图形将它们展示出来。在R中，我们可以使用<code>Rgraphviz</code>包来绘制词条之间的关系图：</p>

<p><code>r
require(Rgraphviz)
plot(dtm, terms = findFreqTerms(dtm, lowfreq = 20))
</code></p>

<p><img src="/images/a42/TM2.2.11.png" alt="plot of chunk
TM2.2.1" /></p>

<p><code>r
## 指定相关性必须在0.5之上才可连线
plot(dtm, terms = findFreqTerms(dtm, lowfreq = 20), corThreshold = 0.5)
</code></p>

<p><img src="/images/a42/TM2.2.12.png" alt="plot of chunk
TM2.2.1" /></p>

<p>在默认不指定<code>terms</code>和<code>corThreshold</code>参数的情况下，<code>plot</code>函数会绘制随机20个词条，相关性至少0.7的图形。</p>

<hr />

<p>当然，我们还可以绘制熟悉的频数直方图：</p>

<p>``` r
freq &lt;- sort(colSums(as.matrix(dtm)), decreasing = TRUE)
tf &lt;- data.frame(term = names(freq), freq = freq)</p>

<p>g &lt;- ggplot(subset(tf, freq &gt; 20), aes(term, freq))
g &lt;- g + geom_bar(stat = “identity”, aes(fill = freq))
print(g)
```</p>

<p><img src="/images/a42/TM2.2.2.png" alt="plot of chunk TM2.2.2" /></p>

<hr />

<p>另外一个比较流行好看的图，应该就是文本云(wordcloud)了，可以使用<code>wordcloud</code>包实现：</p>

<p><code>r
require(wordcloud)
wordcloud(names(freq), freq, min.freq = 5, max.words = 80)
</code></p>

<p><img src="/images/a42/TM2.2.31.png" alt="plot of chunk
TM2.2.3" /></p>

<p><code>r
## 添加颜色
require(RColorBrewer)
wordcloud(names(freq), freq, min.freq = 5, max.words = 80, colors = brewer.pal(8,
    "Paired"))
</code></p>

<p><img src="/images/a42/TM2.2.32.png" alt="plot of chunk
TM2.2.3" /></p>

<p>当然，<code>wordcloud()</code>函数提供了很多选项，可以自行查看，我就不多讲了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据科学19：文本挖掘1-更新]]></title>
    <link href="http://jackycode.github.io/blog/2014/06/25/text-mining1-update/"/>
    <updated>2014-06-25T19:21:26+08:00</updated>
    <id>http://jackycode.github.io/blog/2014/06/25/text-mining1-update</id>
    <content type="html"><![CDATA[<p><img src="/images/article/article41.jpg" alt="article 41" />
<!-- more --></p>

<p>图片由本文中数据生产~</p>

<p><em>“文章原创，转载请注明出处”</em></p>

<hr />

<p>前几天，R中的’tm’包从0.5-10更新到了0.6版本。其中更新了不少的东西，对于上一篇中的代码，已经是不能够正确运行了。所以这里需要先更新一下上一篇中的一些代码，正好可以回顾一些之前的流程。</p>

<p>``` r
## Load Packages needed
require(tm)
require(SnowballC)
require(ggplot2)</p>

<h2 id="loading-corpus-">Loading Corpus 这里直接读成文本格式</h2>
<p>xml.path &lt;- system.file(“texts”, “crude”, package = “tm”)
docs &lt;- Corpus(DirSource(xml.path), readerControl = list(reader = readReut21578XMLasPlain))</p>

<h2 id="section">查看</h2>
<p>docs[[1]]
```</p>

<p><code>
## &lt;&lt;PlainTextDocument (metadata: 15)&gt;&gt;
## Diamond Shamrock Corp said that
## effective today it had cut its contract prices for crude oil by
## 1.50 dlrs a barrel.
##     The reduction brings its posted price for West Texas
## Intermediate to 16.00 dlrs a barrel, the copany said.
##     "The price reduction today was made in the light of falling
## oil product prices and a weak crude oil market," a company
## spokeswoman said.
##     Diamond is the latest in a line of U.S. oil companies that
## have cut its contract, or posted, prices over the last two days
## citing weak oil markets.
##  Reuter
</code></p>

<p><code>r
## 去除特殊字符 上一篇中的代码已不能胜任
## 因为上一篇中的代码会修改Corpus中每个文档的class
## 所以这里需要使用一个新的函数'content_transformer'来保证class还是TextDoument
removeSpecialCharacter &lt;- function(x, pattern) {
    gsub(pattern, " ", x)
}
docs &lt;- tm_map(docs, content_transformer(removeSpecialCharacter), "[@/-]")
docs[[1]]
</code></p>

<p><code>
## &lt;&lt;PlainTextDocument (metadata: 15)&gt;&gt;
## Diamond Shamrock Corp said that
## effective today it had cut its contract prices for crude oil by
## 1.50 dlrs a barrel.
##     The reduction brings its posted price for West Texas
## Intermediate to 16.00 dlrs a barrel, the copany said.
##     "The price reduction today was made in the light of falling
## oil product prices and a weak crude oil market," a company
## spokeswoman said.
##     Diamond is the latest in a line of U.S. oil companies that
## have cut its contract, or posted, prices over the last two days
## citing weak oil markets.
##  Reuter
</code></p>

<p><code>r
## 转换成小写字母 与上面问题类似，需要添加'content_transformer'函数
docs &lt;- tm_map(docs, content_transformer(tolower))
docs[[1]]
</code></p>

<p><code>
## &lt;&lt;PlainTextDocument (metadata: 15)&gt;&gt;
## diamond shamrock corp said that
## effective today it had cut its contract prices for crude oil by
## 1.50 dlrs a barrel.
##     the reduction brings its posted price for west texas
## intermediate to 16.00 dlrs a barrel, the copany said.
##     "the price reduction today was made in the light of falling
## oil product prices and a weak crude oil market," a company
## spokeswoman said.
##     diamond is the latest in a line of u.s. oil companies that
## have cut its contract, or posted, prices over the last two days
## citing weak oil markets.
##  reuter
</code></p>

<p><code>r
## 去除数字
docs &lt;- tm_map(docs, removeNumbers)
docs[[1]]
</code></p>

<p><code>
## &lt;&lt;PlainTextDocument (metadata: 15)&gt;&gt;
## diamond shamrock corp said that
## effective today it had cut its contract prices for crude oil by
## . dlrs a barrel.
##     the reduction brings its posted price for west texas
## intermediate to . dlrs a barrel, the copany said.
##     "the price reduction today was made in the light of falling
## oil product prices and a weak crude oil market," a company
## spokeswoman said.
##     diamond is the latest in a line of u.s. oil companies that
## have cut its contract, or posted, prices over the last two days
## citing weak oil markets.
##  reuter
</code></p>

<p><code>r
## 去除停止词
docs &lt;- tm_map(docs, removeWords, stopwords("english"))
docs[[1]]
</code></p>

<p><code>
## &lt;&lt;PlainTextDocument (metadata: 15)&gt;&gt;
## diamond shamrock corp said
## effective today   cut  contract prices  crude oil
## . dlrs  barrel.
##      reduction brings  posted price  west texas
## intermediate  . dlrs  barrel,  copany said.
##     " price reduction today  made   light  falling
## oil product prices   weak crude oil market,"  company
## spokeswoman said.
##     diamond   latest   line  u.s. oil companies
##  cut  contract,  posted, prices   last two days
## citing weak oil markets.
##  reuter
</code></p>

<p><code>r
## 去除标点符号
docs &lt;- tm_map(docs, removePunctuation)
docs[[1]]
</code></p>

<p><code>
## &lt;&lt;PlainTextDocument (metadata: 15)&gt;&gt;
## diamond shamrock corp said
## effective today   cut  contract prices  crude oil
##  dlrs  barrel
##      reduction brings  posted price  west texas
## intermediate   dlrs  barrel  copany said
##      price reduction today  made   light  falling
## oil product prices   weak crude oil market  company
## spokeswoman said
##     diamond   latest   line  us oil companies
##  cut  contract  posted prices   last two days
## citing weak oil markets
##  reuter
</code></p>

<p><code>r
## 去除多余的空格
docs &lt;- tm_map(docs, stripWhitespace)
docs[[1]]
</code></p>

<p><code>
## &lt;&lt;PlainTextDocument (metadata: 15)&gt;&gt;
## diamond shamrock corp said effective today cut contract prices crude oil dlrs barrel reduction brings posted price west texas intermediate dlrs barrel copany said price reduction today made light falling oil product prices weak crude oil market company spokeswoman said diamond latest line us oil companies cut contract posted prices last two days citing weak oil markets reuter
</code></p>

<p><code>r
## 词干化
docs &lt;- tm_map(docs, stemDocument)
docs[[1]]
</code></p>

<p><code>
## &lt;&lt;PlainTextDocument (metadata: 15)&gt;&gt;
## diamond shamrock corp said effect today cut contract price crude oil dlrs barrel reduct bring post price west texa intermedi dlrs barrel copani said price reduct today made light fall oil product price weak crude oil market compani spokeswoman said diamond latest line us oil compani cut contract post price last two day cite weak oil market reuter
</code></p>

<p><code>r
## 创建Document Term Matrix
dtm &lt;- DocumentTermMatrix(docs)
dtm
</code></p>

<p><code>
## &lt;&lt;DocumentTermMatrix (documents: 20, terms: 780)&gt;&gt;
## Non-/sparse entries: 1570/14030
## Sparsity           : 90%
## Maximal term length: 13
## Weighting          : term frequency (tf)
</code></p>

<p><code>r
inspect(dtm[1:5, 1:10])
</code></p>

<p><code>
## &lt;&lt;DocumentTermMatrix (documents: 5, terms: 10)&gt;&gt;
## Non-/sparse entries: 2/48
## Sparsity           : 96%
## Maximal term length: 7
## Weighting          : term frequency (tf)
##
##      Terms
## Docs  abdul abil abl abroad accept accord across activ add address
##   127     0    0   0      0      0      0      0     0   0       0
##   144     0    2   0      0      0      0      0     0   0       4
##   191     0    0   0      0      0      0      0     0   0       0
##   194     0    0   0      0      0      0      0     0   0       0
##   211     0    0   0      0      0      0      0     0   0       0
</code></p>

<p>到这里，就已经完成了上一篇所做的事情了。留意一下，也可以发现，’tm’包更新过之后，处理的结果与之前有一些不同，可以自己动手试试看，看看哪里不一样？</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据科学18：文本挖掘1]]></title>
    <link href="http://jackycode.github.io/blog/2014/06/18/text-mining1/"/>
    <updated>2014-06-18T15:08:39+08:00</updated>
    <id>http://jackycode.github.io/blog/2014/06/18/text-mining1</id>
    <content type="html"><![CDATA[<p><img src="/images/article/article40.jpg" alt="article 40" />
<!-- more --></p>

<p>图片由本文中数据生产~</p>

<p><em>“文章原创，转载请注明出处”</em></p>

<hr />

<p><strong>文本挖掘</strong>，也称为文本数据挖掘，意思就如字面，对文本数据进行挖掘分析。文本挖掘一般包含：<em>文本分类</em>、<em>文本聚类</em>、<em>概念实体挖掘</em>、<em>自然语言处理</em>等等。接下来，我打算用一个简单的例子，介绍一下R语言文本挖掘的一般过程，顺便介绍一些文本挖掘中的概念。</p>

<p>这边主要使用R中的<code>tm</code>包进行文本挖掘，首先加载Package：</p>

<p><code>r
require(tm)  ## R中处理文本挖掘的框架包
require(ggplot2)
</code></p>

<h3 id="corpus">1. 载入Corpus</h3>
<hr />

<p><strong>Corpus</strong>（语料库），指一系列文档的集合，是<code>tm</code>包管理文件的数据结构。通常，我们需要将一批文档导入成Corpus结构的数据，然后才能进行进一步的处理分析。</p>

<p>文档的格式有非常多的格式，<code>tm</code>包支持的格式其实只占很少的一部分，大致有：text, PDF, Mircosoft Word和XML。所以，如果需要处理的文档，其格式不在这里面的话，就需要对格式进行一些转换。个人建议，将文档格式转换成text或者XML会比较容易处理。我们可以查看一下，<code>tm</code>包支持的文档格式：</p>

<p><code>r
getReaders()
</code></p>

<p><code>
## [1] "readDOC"                 "readPDF"
## [3] "readReut21578XML"        "readReut21578XMLasPlain"
## [5] "readPlain"               "readRCV1"
## [7] "readRCV1asPlain"         "readTabular"
## [9] "readXML"
</code></p>

<p>在<code>tm</code>包中，Corpus可以分为两种。一种是Volatile Corpus，这种数据结构是作为R对象保存在内存中,使用<code>VCorpus()</code>或者<code>Corpus()</code>函数；另一种就是Permanent Corpus，作为R的外部保存，使用<code>PCorpus()</code>函数。显然，如何选择取决于内存大小以及运算速率的要求了。</p>

<p>我们这里使用<code>tm</code>包自带的XML文档数据进行演示：</p>

<p><code>r
xml &lt;- system.file("texts", "crude", package = "tm")  ## 数据所在的目录
docs &lt;- Corpus(DirSource(xml), readerControl = list(reader = readReut21578XML))
</code></p>

<p>这里使用的数据源是<code>DirSource</code>，当然也可以从其他的数据源导入，可以使用<code>getSources()</code>查看：</p>

<p><code>r
getSources()
</code></p>

<p><code>
## [1] "DataframeSource" "DirSource"       "ReutersSource"   "URISource"
## [5] "VectorSource"
</code></p>

<p>如果读取的是其他格式的，就需要指定一些其他的参数，用<code>path</code>表示数据所在的目录：</p>

<p><code>r
## txt
docs &lt;- Corpus(DirSource(&lt;path&gt;))
## PDF
docs &lt;- Corpus(DirSource(&lt;path&gt;), readerControl = list(reader = readPDF))
## 其它的类似
</code></p>

<h3 id="corpus-1">2. 查看Corpus</h3>
<hr />

<p>将数据导入成Corpus之后，我们就需要查看Corpus。</p>

<p><code>r
docs  ## 只显示了Corpus中含有的文档数据数量
</code></p>

<p><code>
## A corpus with 20 text documents
</code></p>

<p><code>r
names(docs)[1:3]  ## 显示前3个文档的名称
</code></p>

<p><code>
## [1] "reut-00001.xml" "reut-00002.xml" "reut-00004.xml"
</code></p>

<p><code>r
summary(docs)  ## 显示更多的meta data，但不显示源信息
</code></p>

<p><code>
## A corpus with 20 text documents
##
## The metadata consists of 2 tag-value pairs and a data frame
## Available tags are:
##   create_date creator
## Available variables in the data frame are:
##   MetaID
</code></p>

<p><code>r
inspect(docs[1])  ## 提取第一篇文档的完整信息、
</code></p>

<p><code>
## A corpus with 1 text document
##
## The metadata consists of 2 tag-value pairs and a data frame
## Available tags are:
##   create_date creator
## Available variables in the data frame are:
##   MetaID
##
## $`reut-00001.xml`
## $doc
## $file
## [1] "&lt;buffer&gt;"
##
## $version
## [1] "1.0"
##
## $children
## $children$REUTERS
## &lt;REUTERS TOPICS="YES" LEWISSPLIT="TRAIN" CGISPLIT="TRAINING-SET" OLDID="5670" NEWID="127"&gt;
##  &lt;DATE&gt;26-FEB-1987 17:00:56.04&lt;/DATE&gt;
##  &lt;TOPICS&gt;
##   &lt;D&gt;crude&lt;/D&gt;
##  &lt;/TOPICS&gt;
##  &lt;PLACES&gt;
##   &lt;D&gt;usa&lt;/D&gt;
##  &lt;/PLACES&gt;
##  &lt;PEOPLE/&gt;
##  &lt;ORGS/&gt;
##  &lt;EXCHANGES/&gt;
##  &lt;COMPANIES/&gt;
##  &lt;UNKNOWN&gt;Y
##    f0119 reute
## u f BC-DIAMOND-SHAMROCK-(DIA   02-26 0097&lt;/UNKNOWN&gt;
##  &lt;TEXT&gt;
##   &lt;TITLE&gt;DIAMOND SHAMROCK (DIA) CUTS CRUDE PRICES&lt;/TITLE&gt;
##   &lt;DATELINE&gt;NEW YORK, FEB 26 -&lt;/DATELINE&gt;
##   &lt;BODY&gt;Diamond Shamrock Corp said that
## effective today it had cut its contract prices for crude oil by
## 1.50 dlrs a barrel.
##     The reduction brings its posted price for West Texas
## Intermediate to 16.00 dlrs a barrel, the copany said.
##     &amp;quot;The price reduction today was made in the light of falling
## oil product prices and a weak crude oil market,&amp;quot; a company
## spokeswoman said.
##     Diamond is the latest in a line of U.S. oil companies that
## have cut its contract, or posted, prices over the last two days
## citing weak oil markets.
##  Reuter&lt;/BODY&gt;
##  &lt;/TEXT&gt;
## &lt;/REUTERS&gt;
##
##
## attr(,"class")
## [1] "XMLDocumentContent"
##
## $dtd
## $external
## NULL
##
## $internal
## NULL
##
## attr(,"class")
## [1] "DTDList"
##
## attr(,"Author")
## character(0)
## attr(,"DateTimeStamp")
## [1] "1987-02-26 17:00:56 GMT"
## attr(,"Description")
## [1] ""
## attr(,"Heading")
## [1] "DIAMOND SHAMROCK (DIA) CUTS CRUDE PRICES"
## attr(,"ID")
## [1] "127"
## attr(,"Language")
## [1] "en"
## attr(,"LocalMetaData")
## attr(,"LocalMetaData")$TOPICS
## [1] "YES"
##
## attr(,"LocalMetaData")$LEWISSPLIT
## [1] "TRAIN"
##
## attr(,"LocalMetaData")$CGISPLIT
## [1] "TRAINING-SET"
##
## attr(,"LocalMetaData")$OLDID
## [1] "5670"
##
## attr(,"LocalMetaData")$Topics
## [1] "crude"
##
## attr(,"LocalMetaData")$Places
## [1] "usa"
##
## attr(,"LocalMetaData")$People
## character(0)
##
## attr(,"LocalMetaData")$Orgs
## character(0)
##
## attr(,"LocalMetaData")$Exchanges
## character(0)
##
## attr(,"Origin")
## [1] "Reuters-21578 XML"
## attr(,"class")
## [1] "Reuters21578Document" "TextDocument"         "XMLDocument"
## [4] "XMLAbstractDocument"  "oldClass"
</code></p>

<p><code>r
## inspect(docs) 可以提取所有文档的完整信息，不过数据量会很大
docs[[1]]  ## 提取第一个文档
</code></p>

<p><code>
## $doc
## $file
## [1] "&lt;buffer&gt;"
##
## $version
## [1] "1.0"
##
## $children
## $children$REUTERS
## &lt;REUTERS TOPICS="YES" LEWISSPLIT="TRAIN" CGISPLIT="TRAINING-SET" OLDID="5670" NEWID="127"&gt;
##  &lt;DATE&gt;26-FEB-1987 17:00:56.04&lt;/DATE&gt;
##  &lt;TOPICS&gt;
##   &lt;D&gt;crude&lt;/D&gt;
##  &lt;/TOPICS&gt;
##  &lt;PLACES&gt;
##   &lt;D&gt;usa&lt;/D&gt;
##  &lt;/PLACES&gt;
##  &lt;PEOPLE/&gt;
##  &lt;ORGS/&gt;
##  &lt;EXCHANGES/&gt;
##  &lt;COMPANIES/&gt;
##  &lt;UNKNOWN&gt;Y
##    f0119 reute
## u f BC-DIAMOND-SHAMROCK-(DIA   02-26 0097&lt;/UNKNOWN&gt;
##  &lt;TEXT&gt;
##   &lt;TITLE&gt;DIAMOND SHAMROCK (DIA) CUTS CRUDE PRICES&lt;/TITLE&gt;
##   &lt;DATELINE&gt;NEW YORK, FEB 26 -&lt;/DATELINE&gt;
##   &lt;BODY&gt;Diamond Shamrock Corp said that
## effective today it had cut its contract prices for crude oil by
## 1.50 dlrs a barrel.
##     The reduction brings its posted price for West Texas
## Intermediate to 16.00 dlrs a barrel, the copany said.
##     &amp;quot;The price reduction today was made in the light of falling
## oil product prices and a weak crude oil market,&amp;quot; a company
## spokeswoman said.
##     Diamond is the latest in a line of U.S. oil companies that
## have cut its contract, or posted, prices over the last two days
## citing weak oil markets.
##  Reuter&lt;/BODY&gt;
##  &lt;/TEXT&gt;
## &lt;/REUTERS&gt;
##
##
## attr(,"class")
## [1] "XMLDocumentContent"
##
## $dtd
## $external
## NULL
##
## $internal
## NULL
##
## attr(,"class")
## [1] "DTDList"
##
## attr(,"Author")
## character(0)
## attr(,"DateTimeStamp")
## [1] "1987-02-26 17:00:56 GMT"
## attr(,"Description")
## [1] ""
## attr(,"Heading")
## [1] "DIAMOND SHAMROCK (DIA) CUTS CRUDE PRICES"
## attr(,"ID")
## [1] "127"
## attr(,"Language")
## [1] "en"
## attr(,"LocalMetaData")
## attr(,"LocalMetaData")$TOPICS
## [1] "YES"
##
## attr(,"LocalMetaData")$LEWISSPLIT
## [1] "TRAIN"
##
## attr(,"LocalMetaData")$CGISPLIT
## [1] "TRAINING-SET"
##
## attr(,"LocalMetaData")$OLDID
## [1] "5670"
##
## attr(,"LocalMetaData")$Topics
## [1] "crude"
##
## attr(,"LocalMetaData")$Places
## [1] "usa"
##
## attr(,"LocalMetaData")$People
## character(0)
##
## attr(,"LocalMetaData")$Orgs
## character(0)
##
## attr(,"LocalMetaData")$Exchanges
## character(0)
##
## attr(,"Origin")
## [1] "Reuters-21578 XML"
## attr(,"class")
## [1] "Reuters21578Document" "TextDocument"         "XMLDocument"
## [4] "XMLAbstractDocument"  "oldClass"
</code></p>

<p><code>r
## docs[['reut-00001.xml']] 同样可以提取第一个文档
</code></p>

<h3 id="section">3. 信息转化</h3>
<hr />

<p>创建好Corpus后，就需要对其进行一些修改，比如去除标点、停止词等等。这里就需要使用到一个函数<code>tm_map()</code>，其可以将转化函数作用到每一个文档数据上。</p>

<h4 id="section-1">1. 转化为纯文本</h4>

<p>如果Corpus中存储的是非纯文本的数据，比如XML格式的数据，那么就需要先将这些数据转换成纯文本格式:</p>

<p><code>r
docs &lt;- tm_map(docs, as.PlainTextDocument)
docs[[1]]
</code></p>

<p><code>
## DIAMOND SHAMROCK (DIA) CUTS CRUDE PRICES
## NEW YORK, FEB 26 -
## Diamond Shamrock Corp said that
## effective today it had cut its contract prices for crude oil by
## 1.50 dlrs a barrel.
##     The reduction brings its posted price for West Texas
## Intermediate to 16.00 dlrs a barrel, the copany said.
##     "The price reduction today was made in the light of falling
## oil product prices and a weak crude oil market," a company
## spokeswoman said.
##     Diamond is the latest in a line of U.S. oil companies that
## have cut its contract, or posted, prices over the last two days
## citing weak oil markets.
##  Reuter
</code></p>

<h4 id="section-2">2. 去除特殊字符</h4>

<p>在文档数据中，可能会存在这样的字符：”/”、”@”、”-“等等。大部分时候，我们需要将其去除掉：</p>

<p><code>r
for (i in seq(docs)) {
    docs[[i]] &lt;- gsub("/", " ", docs[[i]])
    docs[[i]] &lt;- gsub("@", " ", docs[[i]])
    docs[[i]] &lt;- gsub("-", " ", docs[[i]])
}
</code></p>

<p>如果存在更复杂的替换，可以使用正则表达式去解决，这里不做介绍。</p>

<h4 id="section-3">3. 转换成小写</h4>

<p>顾名思义，就是将所有的数据转换成小写字母，这样以便更加容易分析。</p>

<p><code>r
docs &lt;- tm_map(docs, tolower)
docs[[1]]  ## 查看效果
</code></p>

<p><code>
## diamond shamrock (dia) cuts crude prices
## new york, feb 26
## diamond shamrock corp said that
## effective today it had cut its contract prices for crude oil by
## 1.50 dlrs a barrel.
##     the reduction brings its posted price for west texas
## intermediate to 16.00 dlrs a barrel, the copany said.
##     "the price reduction today was made in the light of falling
## oil product prices and a weak crude oil market," a company
## spokeswoman said.
##     diamond is the latest in a line of u.s. oil companies that
## have cut its contract, or posted, prices over the last two days
## citing weak oil markets.
##  reuter
</code></p>

<h4 id="section-4">4. 去除数字</h4>

<p>有些时候，我们需要将文档中的数字去除掉：</p>

<p><code>r
docs &lt;- tm_map(docs, removeNumbers)
docs[[1]]
</code></p>

<p><code>
## diamond shamrock (dia) cuts crude prices
## new york, feb
## diamond shamrock corp said that
## effective today it had cut its contract prices for crude oil by
## . dlrs a barrel.
##     the reduction brings its posted price for west texas
## intermediate to . dlrs a barrel, the copany said.
##     "the price reduction today was made in the light of falling
## oil product prices and a weak crude oil market," a company
## spokeswoman said.
##     diamond is the latest in a line of u.s. oil companies that
## have cut its contract, or posted, prices over the last two days
## citing weak oil markets.
##  reuter
</code></p>

<h4 id="section-5">5. 去除停止词</h4>

<p><code>r
docs &lt;- tm_map(docs, removeWords, stopwords("english"))
docs[[1]]
</code></p>

<p><code>
## diamond shamrock (dia) cuts crude prices
## new york, feb
## diamond shamrock corp said
## effective today   cut  contract prices  crude oil
## . dlrs  barrel.
##      reduction brings  posted price  west texas
## intermediate  . dlrs  barrel,  copany said.
##     " price reduction today  made   light  falling
## oil product prices   weak crude oil market,"  company
## spokeswoman said.
##     diamond   latest   line  u.s. oil companies
##  cut  contract,  posted, prices   last two days
## citing weak oil markets.
##  reuter
</code></p>

<h4 id="section-6">6. 去除标点</h4>

<p><code>r
docs &lt;- tm_map(docs, removePunctuation)
docs[[1]]
</code></p>

<p><code>
## diamond shamrock dia cuts crude prices
## new york feb
## diamond shamrock corp said
## effective today   cut  contract prices  crude oil
##  dlrs  barrel
##      reduction brings  posted price  west texas
## intermediate   dlrs  barrel  copany said
##      price reduction today  made   light  falling
## oil product prices   weak crude oil market  company
## spokeswoman said
##     diamond   latest   line  us oil companies
##  cut  contract  posted prices   last two days
## citing weak oil markets
##  reuter
</code></p>

<h4 id="section-7">7. 去除多余的空格</h4>

<p><code>r
docs &lt;- tm_map(docs, stripWhitespace)
docs[[1]]
</code></p>

<p><code>
## diamond shamrock dia cuts crude prices
## new york feb
## diamond shamrock corp said effective today cut contract prices crude oil dlrs barrel reduction brings posted price west texas intermediate dlrs barrel copany said price reduction today made light falling oil product prices weak crude oil market company spokeswoman said diamond latest line us oil companies cut contract posted prices last two days citing weak oil markets reuter
</code></p>

<h4 id="stemming">8. Stemming(词干化)</h4>

<p>首先介绍一下什么是Stemming，我们知道在英文中一个单词会存在很多形式，比如说复数形式、过去分词等等。但其实它们外表看起来虽不一样，但实际上是一样的。所以在处理分析的时候，就需要将这些单词都转换成其本身。在R中可以使用<code>SnowballC</code>这个包来处理Stemming，举个例子：</p>

<p><code>r
require(SnowballC)
</code></p>

<p><code>
## Loading required package: SnowballC
</code></p>

<p><code>r
exam &lt;- c("prices, price, doing")
stemDocument(exam)
</code></p>

<p><code>
## [1] "prices, price, do"
</code></p>

<p>对于我们的例子：</p>

<p><code>r
require(SnowballC)
docs &lt;- tm_map(docs, stemDocument)
docs[[1]]
</code></p>

<p><code>
## diamond shamrock dia cut crude price
## new york feb
## diamond shamrock corp said effect today cut contract price crude oil dlrs barrel reduct bring post price west texa intermedi dlrs barrel copani said price reduct today made light fall oil product price weak crude oil market compani spokeswoman said diamond latest line us oil compani cut contract post price last two day cite weak oil market reuter
</code></p>

<h3 id="section-8">4. 创建词条-文档关系矩阵</h3>
<hr />

<p>文本挖掘中，词条-文档关系矩阵是构建模型的基础，后续分析建模都是建立在这个矩阵之上的。首先来了解一下这个矩阵，举个例子：</p>

<p>我们有两篇文档，内容分别为：text mining 和 data mining and text mining。 那么对应的矩阵为：</p>

<p><code>r
d.Exam &lt;- c("text mining", "data mining and text mining")
doc.Exam &lt;- Corpus(VectorSource(d.Exam))
dtm.Exam &lt;- DocumentTermMatrix(doc.Exam)
inspect(dtm.Exam)
</code></p>

<p><code>
## A document-term matrix (2 documents, 4 terms)
##
## Non-/sparse entries: 6/2
## Sparsity           : 25%
## Maximal term length: 6
## Weighting          : term frequency (tf)
##
##     Terms
## Docs and data mining text
##    1   0    0      1    1
##    2   1    1      2    1
</code></p>

<p>可以看到，词条-文档关系矩阵其实就是将文档作为列，词条作为行，矩阵的每个位置就是对应的词条在对应的文档中出现的次数。</p>

<p>对于我们的例子，可以这样来生产词条-文档矩阵：</p>

<p><code>r
dtm &lt;- DocumentTermMatrix(docs)
inspect(dtm[1:5, 1:10])
</code></p>

<p><code>
## A document-term matrix (5 documents, 10 terms)
##
## Non-/sparse entries: 1/49
## Sparsity           : 98%
## Maximal term length: 6
## Weighting          : term frequency (tf)
##
##      Terms
## Docs  abdul abil abl abroad abu accept accord across activ add
##   127     0    0   0      0   0      0      0      0     0   0
##   144     0    2   0      0   0      0      0      0     0   0
##   191     0    0   0      0   0      0      0      0     0   0
##   194     0    0   0      0   0      0      0      0     0   0
##   211     0    0   0      0   0      0      0      0     0   0
</code></p>

<p>到这里，我们就已经生成了词条-文档矩阵。下一次，就来看看如何对这个矩阵进行一些操作，以及如何利用这个矩阵进行后续的建模分析。</p>

]]></content>
  </entry>
  
</feed>
